{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to MIRIX","text":"<p>MIRIX is a multi-agent personal assistant designed to track on-screen activities and answer user questions intelligently. By capturing real-time visual data and consolidating it into structured memories, MIRIX transforms raw inputs into a rich knowledge base that adapts to your digital experiences.</p>   [![GitHub stars](https://img.shields.io/github/stars/Mirix-AI/MIRIX?style=social)](https://github.com/Mirix-AI/MIRIX/stargazers) [![GitHub forks](https://img.shields.io/github/forks/Mirix-AI/MIRIX?style=social)](https://github.com/Mirix-AI/MIRIX/network/members) [![GitHub issues](https://img.shields.io/github/issues/Mirix-AI/MIRIX)](https://github.com/Mirix-AI/MIRIX/issues) [![GitHub license](https://img.shields.io/github/license/Mirix-AI/MIRIX)](https://github.com/Mirix-AI/MIRIX/blob/main/LICENSE) [![GitHub release](https://img.shields.io/github/v/release/Mirix-AI/MIRIX)](https://github.com/Mirix-AI/MIRIX/releases)   <ul> <li> <p> Getting Started</p> <p>Installation, overview, and quick start guides to get you up and running with MIRIX.</p> <p> Get Started</p> </li> <li> <p> Architecture</p> <p>Learn about the multi-agent system, memory components, and search capabilities that power MIRIX.</p> <p> View Architecture</p> </li> <li> <p> User Guide</p> <p>Comprehensive guides for using the desktop app, backend, and managing your memories.</p> <p> User Guide</p> </li> <li> <p> API Reference</p> <p>Complete API documentation for agent and memory management endpoints.</p> <p> API Docs</p> </li> <li> <p> Advanced</p> <p>Advanced topics including backup &amp; restore, performance optimization, and security settings.</p> <p> Advanced Topics</p> </li> <li> <p> Contributing</p> <p>Learn how to contribute to the MIRIX project and join our community.</p> <p> Contribute</p> </li> </ul> <p>Ready to transform your digital experience with intelligent memory? </p>"},{"location":"contributing/","title":"Contributing to MIRIX","text":"<p>Thank you for your interest in contributing to MIRIX! This guide will help you get started with contributing to our multi-agent personal assistant project.</p>"},{"location":"contributing/#quick-start-for-contributors","title":"\ud83d\ude80 Quick Start for Contributors","text":""},{"location":"contributing/#development-setup","title":"Development Setup","text":"<ol> <li> <p>Fork and Clone <pre><code>git clone https://github.com/YOUR_USERNAME/MIRIX.git\ncd MIRIX\n</code></pre></p> </li> <li> <p>Set up Development Environment <pre><code># Create virtual environment\npython -m venv mirix-dev\nsource mirix-dev/bin/activate  # On Windows: mirix-dev\\Scripts\\activate\n\n# Install development dependencies\npip install -r requirements-dev.txt\n</code></pre></p> </li> <li> <p>Configure Pre-commit Hooks <pre><code>pre-commit install\n</code></pre></p> </li> </ol>"},{"location":"contributing/#development-workflow","title":"\ud83d\udee0\ufe0f Development Workflow","text":""},{"location":"contributing/#branch-structure","title":"Branch Structure","text":"<ul> <li><code>main</code> - Production-ready code</li> <li><code>develop</code> - Integration branch for features</li> <li><code>feature/*</code> - New features</li> <li><code>bugfix/*</code> - Bug fixes</li> <li><code>hotfix/*</code> - Critical production fixes</li> </ul>"},{"location":"contributing/#making-changes","title":"Making Changes","text":"<ol> <li> <p>Create a Feature Branch <pre><code>git checkout -b feature/your-feature-name\n</code></pre></p> </li> <li> <p>Make Your Changes</p> </li> <li>Write clean, documented code</li> <li>Follow our coding standards</li> <li> <p>Add tests for new functionality</p> </li> <li> <p>Test Your Changes <pre><code># Run unit tests\npytest tests/\n\n# Run integration tests\npytest tests/integration/\n\n# Check code quality\nflake8 src/\nblack src/\n</code></pre></p> </li> <li> <p>Submit a Pull Request</p> </li> <li>Use our PR template</li> <li>Include clear description of changes</li> <li>Reference related issues</li> </ol>"},{"location":"contributing/#testing-guidelines","title":"\ud83e\uddea Testing Guidelines","text":""},{"location":"contributing/#test-structure","title":"Test Structure","text":"<pre><code>tests/\n\u251c\u2500\u2500 unit/           # Unit tests for individual components\n\u251c\u2500\u2500 integration/    # Integration tests for agent interactions\n\u251c\u2500\u2500 memory/         # Tests for memory components\n\u251c\u2500\u2500 agents/         # Tests for individual agents\n\u2514\u2500\u2500 fixtures/       # Test data and fixtures\n</code></pre>"},{"location":"contributing/#running-tests","title":"Running Tests","text":"<pre><code># All tests\npytest\n\n# Specific test categories\npytest tests/unit/\npytest tests/integration/\npytest tests/memory/\n\n# With coverage\npytest --cov=src tests/\n</code></pre>"},{"location":"contributing/#writing-tests","title":"Writing Tests","text":"<pre><code>import pytest\nfrom mirix.agents import MetaAgent\nfrom mirix.memory import CoreMemory\n\nclass TestMetaAgent:\n    def test_agent_initialization(self):\n        agent = MetaAgent()\n        assert agent.name == \"MetaAgent\"\n        assert agent.is_active == True\n\n    def test_memory_interaction(self):\n        agent = MetaAgent()\n        memory = CoreMemory()\n\n        result = agent.process_screenshot(\"test_screenshot.png\")\n        assert result is not None\n</code></pre>"},{"location":"contributing/#architecture-guidelines","title":"\ud83c\udfd7\ufe0f Architecture Guidelines","text":""},{"location":"contributing/#agent-development","title":"Agent Development","text":"<p>When creating new agents:</p> <ol> <li> <p>Inherit from BaseAgent <pre><code>from mirix.core import BaseAgent\n\nclass YourAgent(BaseAgent):\n    def __init__(self):\n        super().__init__(name=\"YourAgent\")\n\n    def process(self, data):\n        # Your agent logic here\n        pass\n</code></pre></p> </li> <li> <p>Follow Agent Patterns</p> </li> <li>Single responsibility principle</li> <li>Clear input/output interfaces</li> <li>Error handling and logging</li> <li>Memory interaction protocols</li> </ol>"},{"location":"contributing/#memory-component-guidelines","title":"Memory Component Guidelines","text":"<p>For new memory types:</p> <ol> <li> <p>Implement Memory Interface <pre><code>from mirix.memory import BaseMemory\n\nclass YourMemory(BaseMemory):\n    def store(self, data):\n        # Storage logic\n        pass\n\n    def retrieve(self, query):\n        # Retrieval logic\n        pass\n</code></pre></p> </li> <li> <p>Database Schema</p> </li> <li>Use Alembic for migrations</li> <li>Follow naming conventions</li> <li>Add proper indexes</li> </ol>"},{"location":"contributing/#coding-standards","title":"\ud83d\udccb Coding Standards","text":""},{"location":"contributing/#python-style-guide","title":"Python Style Guide","text":"<p>We follow PEP 8 with these additions:</p> <ul> <li>Line Length: 88 characters (Black default)</li> <li>Import Order: isort with Black compatibility</li> <li>Docstrings: Google style docstrings</li> <li>Type Hints: Use for all public functions</li> </ul>"},{"location":"contributing/#code-quality-tools","title":"Code Quality Tools","text":"<pre><code># Formatting\nblack src/\nisort src/\n\n# Linting\nflake8 src/\npylint src/\n\n# Type checking\nmypy src/\n</code></pre>"},{"location":"contributing/#documentation","title":"Documentation","text":"<ul> <li>Docstrings: Required for all public methods</li> <li>Type Hints: Required for function signatures</li> <li>Comments: Explain complex logic, not obvious code</li> <li>README: Update if adding new features</li> </ul> <p>Example:</p> <pre><code>def search_memory(\n    self, \n    query: str, \n    memory_type: Optional[str] = None,\n    limit: int = 10\n) -&gt; List[MemoryResult]:\n    \"\"\"Search across memory components for relevant information.\n\n    Args:\n        query: Search query text\n        memory_type: Optional memory type filter\n        limit: Maximum number of results to return\n\n    Returns:\n        List of memory results sorted by relevance\n\n    Raises:\n        ValueError: If query is empty or invalid\n        MemoryError: If memory system is unavailable\n    \"\"\"\n    pass\n</code></pre>"},{"location":"contributing/#bug-reports","title":"\ud83d\udc1b Bug Reports","text":""},{"location":"contributing/#before-reporting","title":"Before Reporting","text":"<ol> <li>Check existing issues</li> <li>Reproduce with latest version</li> <li>Test with minimal configuration</li> </ol>"},{"location":"contributing/#bug-report-template","title":"Bug Report Template","text":"<pre><code>**Bug Description**\nClear description of the bug\n\n**Steps to Reproduce**\n1. Step one\n2. Step two\n3. See error\n\n**Expected Behavior**\nWhat should happen\n\n**Environment**\n- OS: [e.g., macOS 14.0]\n- Python: [e.g., 3.11.5]\n- MIRIX Version: [e.g., 1.2.0]\n- Database: [PostgreSQL 17 / SQLite]\n\n**Additional Context**\nLogs, screenshots, etc.\n</code></pre>"},{"location":"contributing/#feature-requests","title":"\ud83d\udca1 Feature Requests","text":""},{"location":"contributing/#proposal-process","title":"Proposal Process","text":"<ol> <li>Check Roadmap: Review our project roadmap</li> <li>Open Discussion: Create a GitHub Discussion</li> <li>RFC Process: For major features, write an RFC</li> <li>Implementation: After approval, implement the feature</li> </ol>"},{"location":"contributing/#feature-request-template","title":"Feature Request Template","text":"<pre><code>**Feature Description**\nClear description of the proposed feature\n\n**Use Case**\nWhy is this feature needed?\n\n**Proposed Solution**\nHow should it work?\n\n**Alternatives Considered**\nOther approaches you've considered\n\n**Additional Context**\nMockups, examples, etc.\n</code></pre>"},{"location":"contributing/#release-process","title":"\ud83d\udd04 Release Process","text":""},{"location":"contributing/#versioning","title":"Versioning","text":"<p>We use Semantic Versioning (SemVer): - <code>MAJOR.MINOR.PATCH</code> - Major: Breaking changes - Minor: New features (backward compatible) - Patch: Bug fixes</p>"},{"location":"contributing/#release-checklist","title":"Release Checklist","text":"<ul> <li>[ ] All tests passing</li> <li>[ ] Documentation updated</li> <li>[ ] CHANGELOG.md updated</li> <li>[ ] Version bumped</li> <li>[ ] Tag created</li> <li>[ ] Release notes written</li> </ul>"},{"location":"contributing/#community-guidelines","title":"\ud83e\udd1d Community Guidelines","text":""},{"location":"contributing/#code-of-conduct","title":"Code of Conduct","text":"<ul> <li>Be respectful and inclusive</li> <li>Provide constructive feedback</li> <li>Help newcomers learn</li> <li>Keep discussions on-topic</li> </ul>"},{"location":"contributing/#communication-channels","title":"Communication Channels","text":"<ul> <li>GitHub Issues: Bug reports and feature requests</li> <li>GitHub Discussions: General questions and ideas</li> <li>Email: yuw164@ucsd.edu for sensitive matters</li> </ul>"},{"location":"contributing/#additional-resources","title":"\ud83d\udcda Additional Resources","text":""},{"location":"contributing/#documentation_1","title":"Documentation","text":"<ul> <li>Architecture Overview</li> <li>Memory System Design</li> <li>API Reference</li> <li>Development Setup</li> </ul>"},{"location":"contributing/#external-resources","title":"External Resources","text":"<ul> <li>PostgreSQL Documentation</li> <li>Python Async/Await Guide</li> <li>Pytest Documentation</li> </ul>"},{"location":"contributing/#recognition","title":"\ud83d\ude4f Recognition","text":"<p>Contributors are recognized in: - GitHub contributor graphs - Release notes - CONTRIBUTORS.md file - Special mentions for significant contributions</p> <p>Thank you for helping make MIRIX better! \ud83d\ude80 </p>"},{"location":"advanced/backup-restore/","title":"Backup &amp; Restore","text":"<p>MIRIX provides built-in backup and restore functionality for your agent data, ensuring your memories and configurations are safe and portable.</p>"},{"location":"advanced/backup-restore/#overview","title":"Overview","text":"<p>The backup system automatically handles both PostgreSQL and SQLite databases, preserving all your conversations, memories, and agent configurations in a portable format.</p>"},{"location":"advanced/backup-restore/#what-gets-backed-up","title":"What Gets Backed Up","text":"<pre><code>graph TD\n    A[Agent Backup] --&gt; B[Memory Data]\n    A --&gt; C[Configuration Files]\n    A --&gt; D[User Preferences]\n    A --&gt; E[Conversation History]\n\n    B --&gt; F[Core Memory]\n    B --&gt; G[Episodic Memory]\n    B --&gt; H[Semantic Memory]\n    B --&gt; I[Procedural Memory]\n    B --&gt; J[Resource Memory]\n    B --&gt; K[Knowledge Vault]\n\n    C --&gt; L[mirix.yaml]\n    C --&gt; M[Environment Settings]\n\n    D --&gt; N[Privacy Settings]\n    D --&gt; O[Search Preferences]\n\n    E --&gt; P[Chat Logs]\n    E --&gt; Q[Agent Responses]</code></pre>"},{"location":"advanced/backup-restore/#prerequisites","title":"Prerequisites","text":""},{"location":"advanced/backup-restore/#postgresql-setup","title":"PostgreSQL Setup","text":"<p>Since backups use <code>pg_dump</code> to save the database, ensure PostgreSQL tools are accessible:</p> <pre><code># macOS with Homebrew\nexport PATH=\"$(brew --prefix postgresql@17)/bin:$PATH\"\n\n# Verify pg_dump is available\nwhich pg_dump\n</code></pre> <p>PATH Configuration Required</p> <p>Without proper PATH configuration, backup operations will fail with \"pg_dump: No such file or directory\" error.</p>"},{"location":"advanced/backup-restore/#permissions","title":"Permissions","text":"<p>Ensure your user has proper database permissions:</p> <pre><code>-- Check current user permissions\nSELECT current_user, current_database();\n\n-- Verify backup permissions\nSELECT has_database_privilege(current_user, current_database(), 'CONNECT');\n</code></pre>"},{"location":"advanced/backup-restore/#creating-backups","title":"Creating Backups","text":""},{"location":"advanced/backup-restore/#basic-backup","title":"Basic Backup","text":"<pre><code>from mirix.agent import AgentWrapper\n\n# Initialize agent\nagent = AgentWrapper(\"./configs/mirix.yaml\")\n\n# Create backup\nresult = agent.save_agent(\"./my_backup\")\nprint(result['message'])  # \"Agent state saved successfully...\"\n</code></pre>"},{"location":"advanced/backup-restore/#advanced-backup-options","title":"Advanced Backup Options","text":"<pre><code># Backup with custom options\nresult = agent.save_agent(\n    backup_path=\"./backups/mirix_backup_2024_03_15\",\n    include_logs=True,\n    compress=True,\n    verify_integrity=True\n)\n\nif result['success']:\n    print(f\"Backup created: {result['backup_path']}\")\n    print(f\"Size: {result['size_mb']} MB\")\n    print(f\"Files: {result['file_count']}\")\nelse:\n    print(f\"Backup failed: {result['error']}\")\n</code></pre>"},{"location":"advanced/backup-restore/#automated-backup-schedule","title":"Automated Backup Schedule","text":"<pre><code>import schedule\nimport time\nfrom datetime import datetime\n\ndef create_daily_backup():\n    \"\"\"Create daily backup with timestamp\"\"\"\n    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n    backup_path = f\"./backups/daily_backup_{timestamp}\"\n\n    agent = AgentWrapper(\"./configs/mirix.yaml\")\n    result = agent.save_agent(backup_path)\n\n    if result['success']:\n        print(f\"Daily backup created: {backup_path}\")\n        # Clean up old backups (keep last 7 days)\n        cleanup_old_backups(\"./backups\", days_to_keep=7)\n    else:\n        print(f\"Backup failed: {result['error']}\")\n\n# Schedule daily backups\nschedule.every().day.at(\"02:00\").do(create_daily_backup)\n\n# Keep scheduler running\nwhile True:\n    schedule.run_pending()\n    time.sleep(60)\n</code></pre>"},{"location":"advanced/backup-restore/#backup-structure","title":"Backup Structure","text":""},{"location":"advanced/backup-restore/#directory-layout","title":"Directory Layout","text":"<pre><code>my_backup/\n\u251c\u2500\u2500 metadata.json           # Backup information and checksums\n\u251c\u2500\u2500 database/\n\u2502   \u251c\u2500\u2500 mirix_dump.sql     # PostgreSQL database dump\n\u2502   \u2514\u2500\u2500 schema_info.json   # Database schema information\n\u251c\u2500\u2500 config/\n\u2502   \u251c\u2500\u2500 mirix.yaml         # Configuration file\n\u2502   \u2514\u2500\u2500 environment.env    # Environment variables (sanitized)\n\u251c\u2500\u2500 memories/\n\u2502   \u251c\u2500\u2500 core_memory.json   # Core memory backup\n\u2502   \u251c\u2500\u2500 episodic_memory.json\n\u2502   \u251c\u2500\u2500 semantic_memory.json\n\u2502   \u251c\u2500\u2500 procedural_memory.json\n\u2502   \u251c\u2500\u2500 resource_memory.json\n\u2502   \u2514\u2500\u2500 knowledge_vault.json\n\u251c\u2500\u2500 logs/\n\u2502   \u251c\u2500\u2500 agent.log          # Agent logs\n\u2502   \u2514\u2500\u2500 security.log       # Security audit logs\n\u2514\u2500\u2500 verification/\n    \u251c\u2500\u2500 checksums.md5      # File integrity checksums\n    \u2514\u2500\u2500 backup_report.txt  # Backup verification report\n</code></pre>"},{"location":"advanced/backup-restore/#metadata-format","title":"Metadata Format","text":"<pre><code>{\n  \"backup_info\": {\n    \"version\": \"1.0.0\",\n    \"timestamp\": \"2024-03-15T14:30:00Z\",\n    \"mirix_version\": \"2024.04.27\",\n    \"database_type\": \"postgresql\",\n    \"backup_size_bytes\": 52428800,\n    \"file_count\": 15\n  },\n  \"checksums\": {\n    \"database/mirix_dump.sql\": \"a1b2c3d4e5f6...\",\n    \"config/mirix.yaml\": \"f6e5d4c3b2a1...\",\n    \"memories/core_memory.json\": \"1a2b3c4d5e6f...\"\n  },\n  \"verification\": {\n    \"integrity_check\": \"passed\",\n    \"completeness_check\": \"passed\",\n    \"compression_ratio\": 0.65\n  }\n}\n</code></pre>"},{"location":"advanced/backup-restore/#restoring-from-backups","title":"Restoring from Backups","text":""},{"location":"advanced/backup-restore/#method-1-restore-during-initialization-recommended","title":"Method 1: Restore During Initialization (Recommended)","text":"<pre><code># Initialize agent with backup data\nagent = AgentWrapper(\n    config_path=\"./configs/mirix.yaml\",\n    load_from=\"./my_backup\"\n)\n\nprint(\"Agent restored from backup\")\n</code></pre>"},{"location":"advanced/backup-restore/#method-2-load-backup-after-creation","title":"Method 2: Load Backup After Creation","text":"<pre><code># Create agent normally\nagent = AgentWrapper(\"./configs/mirix.yaml\")\n\n# Then load backup data\nresult = agent.load_agent(\"./my_backup\")\n\nif result['success']:\n    print(f\"Backup restored successfully\")\n    print(f\"Restored {result['memory_count']} memories\")\n    print(f\"Restored {result['conversation_count']} conversations\")\nelse:\n    print(f\"Restore failed: {result['error']}\")\n</code></pre>"},{"location":"advanced/backup-restore/#selective-restore","title":"Selective Restore","text":"<pre><code># Restore only specific components\nresult = agent.load_agent(\n    backup_path=\"./my_backup\",\n    restore_components={\n        \"memories\": True,\n        \"conversations\": True,\n        \"config\": False,  # Keep current config\n        \"logs\": False     # Skip logs\n    }\n)\n</code></pre>"},{"location":"advanced/backup-restore/#backup-verification","title":"Backup Verification","text":""},{"location":"advanced/backup-restore/#integrity-checks","title":"Integrity Checks","text":"<pre><code>def verify_backup(backup_path):\n    \"\"\"Verify backup integrity\"\"\"\n    verification_results = {\n        \"file_integrity\": check_file_checksums(backup_path),\n        \"database_integrity\": verify_database_dump(backup_path),\n        \"memory_completeness\": verify_memory_data(backup_path),\n        \"config_validity\": verify_config_files(backup_path)\n    }\n\n    all_passed = all(verification_results.values())\n\n    return {\n        \"valid\": all_passed,\n        \"results\": verification_results\n    }\n\n# Usage\nbackup_path = \"./my_backup\"\nverification = verify_backup(backup_path)\n\nif verification[\"valid\"]:\n    print(\"Backup verification passed\")\nelse:\n    print(\"Backup verification failed:\")\n    for check, result in verification[\"results\"].items():\n        if not result:\n            print(f\"  - {check}: FAILED\")\n</code></pre>"},{"location":"advanced/backup-restore/#automated-verification","title":"Automated Verification","text":"<pre><code># Verify backup immediately after creation\nresult = agent.save_agent(\n    backup_path=\"./verified_backup\",\n    verify_after_backup=True\n)\n\nif result['verification_passed']:\n    print(\"Backup created and verified successfully\")\nelse:\n    print(f\"Backup verification failed: {result['verification_errors']}\")\n</code></pre>"},{"location":"advanced/backup-restore/#migration-between-systems","title":"Migration Between Systems","text":""},{"location":"advanced/backup-restore/#export-for-migration","title":"Export for Migration","text":"<pre><code>def export_for_migration(source_agent, export_path):\n    \"\"\"Export agent data for migration to new system\"\"\"\n\n    # Create comprehensive backup\n    backup_result = source_agent.save_agent(\n        backup_path=export_path,\n        include_logs=True,\n        include_config=True,\n        sanitize_sensitive=True  # Remove API keys, etc.\n    )\n\n    # Create migration guide\n    migration_guide = {\n        \"source_system\": get_system_info(),\n        \"mirix_version\": get_mirix_version(),\n        \"database_type\": get_database_type(),\n        \"migration_steps\": [\n            \"1. Install MIRIX on target system\",\n            \"2. Configure database (PostgreSQL recommended)\",\n            \"3. Set up environment variables\",\n            \"4. Restore from this backup\",\n            \"5. Verify all memories are accessible\"\n        ],\n        \"notes\": [\n            \"API keys and sensitive data have been sanitized\",\n            \"Update environment variables after restore\",\n            \"Test search functionality after migration\"\n        ]\n    }\n\n    # Save migration guide\n    with open(f\"{export_path}/MIGRATION_GUIDE.json\", \"w\") as f:\n        json.dump(migration_guide, f, indent=2)\n\n    return backup_result\n\n# Usage\nexport_result = export_for_migration(agent, \"./migration_export\")\n</code></pre>"},{"location":"advanced/backup-restore/#import-on-new-system","title":"Import on New System","text":"<pre><code>def import_from_migration(backup_path, new_config_path):\n    \"\"\"Import agent data on new system\"\"\"\n\n    # Verify migration package\n    if not verify_migration_package(backup_path):\n        raise ValueError(\"Invalid migration package\")\n\n    # Initialize new agent with migrated data\n    agent = AgentWrapper(\n        config_path=new_config_path,\n        load_from=backup_path\n    )\n\n    # Run post-migration verification\n    verification_results = run_post_migration_tests(agent)\n\n    return {\n        \"agent\": agent,\n        \"verification\": verification_results\n    }\n\n# Usage on new system\nimport_result = import_from_migration(\n    backup_path=\"./migration_export\",\n    new_config_path=\"./configs/mirix.yaml\"\n)\n\nif import_result[\"verification\"][\"all_passed\"]:\n    print(\"Migration completed successfully\")\nelse:\n    print(\"Migration completed with warnings:\")\n    for warning in import_result[\"verification\"][\"warnings\"]:\n        print(f\"  - {warning}\")\n</code></pre>"},{"location":"advanced/backup-restore/#backup-management","title":"Backup Management","text":""},{"location":"advanced/backup-restore/#cleanup-old-backups","title":"Cleanup Old Backups","text":"<pre><code>def cleanup_old_backups(backup_dir, days_to_keep=30):\n    \"\"\"Remove backups older than specified days\"\"\"\n    import os\n    import time\n    from pathlib import Path\n\n    backup_path = Path(backup_dir)\n    current_time = time.time()\n    cutoff_time = current_time - (days_to_keep * 24 * 60 * 60)\n\n    removed_count = 0\n    for backup_folder in backup_path.iterdir():\n        if backup_folder.is_dir():\n            folder_time = backup_folder.stat().st_mtime\n            if folder_time &lt; cutoff_time:\n                shutil.rmtree(backup_folder)\n                removed_count += 1\n                print(f\"Removed old backup: {backup_folder.name}\")\n\n    print(f\"Cleaned up {removed_count} old backups\")\n    return removed_count\n\n# Usage\ncleanup_old_backups(\"./backups\", days_to_keep=7)\n</code></pre>"},{"location":"advanced/backup-restore/#backup-size-monitoring","title":"Backup Size Monitoring","text":"<pre><code>def monitor_backup_sizes(backup_dir):\n    \"\"\"Monitor backup sizes and growth\"\"\"\n    import os\n    from pathlib import Path\n\n    backup_path = Path(backup_dir)\n    backup_info = []\n\n    for backup_folder in backup_path.iterdir():\n        if backup_folder.is_dir():\n            size = sum(f.stat().st_size for f in backup_folder.rglob('*') if f.is_file())\n            backup_info.append({\n                \"name\": backup_folder.name,\n                \"size_mb\": size / (1024 * 1024),\n                \"created\": backup_folder.stat().st_ctime\n            })\n\n    # Sort by creation time\n    backup_info.sort(key=lambda x: x[\"created\"])\n\n    # Calculate growth trends\n    if len(backup_info) &gt; 1:\n        avg_growth = (backup_info[-1][\"size_mb\"] - backup_info[0][\"size_mb\"]) / len(backup_info)\n        print(f\"Average backup size growth: {avg_growth:.2f} MB per backup\")\n\n    return backup_info\n\n# Usage\nbackup_stats = monitor_backup_sizes(\"./backups\")\nfor backup in backup_stats[-5:]:  # Show last 5 backups\n    print(f\"{backup['name']}: {backup['size_mb']:.2f} MB\")\n</code></pre>"},{"location":"advanced/backup-restore/#troubleshooting","title":"Troubleshooting","text":""},{"location":"advanced/backup-restore/#common-backup-issues","title":"Common Backup Issues","text":"<p>\\\"pg_dump: No such file or directory\\\" error</p> <p>PostgreSQL tools are not in your PATH: <pre><code># Add PostgreSQL to PATH\nexport PATH=\"$(brew --prefix postgresql@17)/bin:$PATH\"\n\n# Add to your shell profile for persistence\necho 'export PATH=\"$(brew --prefix postgresql@17)/bin:$PATH\"' &gt;&gt; ~/.zshrc\n</code></pre></p> <p>\\\"Permission denied\\\" during backup</p> <p>Check database permissions: <pre><code>-- Connect to your database\npsql -U $(whoami) -d mirix\n\n-- Check permissions\n\\du\n</code></pre></p> <p>Backup corruption or incomplete</p> <p>Verify backup integrity: <pre><code>verification = verify_backup(\"./my_backup\")\nif not verification[\"valid\"]:\n    print(\"Backup is corrupted, create a new one\")\n    result = agent.save_agent(\"./new_backup\", verify_after_backup=True)\n</code></pre></p> <p>Restore fails with version mismatch</p> <p>Check MIRIX version compatibility: <pre><code># Check backup version\nwith open(\"./my_backup/metadata.json\") as f:\n    metadata = json.load(f)\n    backup_version = metadata[\"backup_info\"][\"mirix_version\"]\n    print(f\"Backup version: {backup_version}\")\n    print(f\"Current version: {get_mirix_version()}\")\n</code></pre></p>"},{"location":"advanced/backup-restore/#recovery-strategies","title":"Recovery Strategies","text":""},{"location":"advanced/backup-restore/#partial-restore","title":"Partial Restore","text":"<pre><code>def recover_specific_memories(backup_path, memory_types):\n    \"\"\"Recover only specific memory types\"\"\"\n\n    agent = AgentWrapper(\"./configs/mirix.yaml\")\n\n    for memory_type in memory_types:\n        memory_file = f\"{backup_path}/memories/{memory_type}_memory.json\"\n        if os.path.exists(memory_file):\n            with open(memory_file) as f:\n                memory_data = json.load(f)\n\n            # Restore this memory type\n            agent.restore_memory_type(memory_type, memory_data)\n            print(f\"Restored {memory_type} memory\")\n\n    return agent\n\n# Usage - recover only core and semantic memories\nagent = recover_specific_memories(\n    \"./my_backup\", \n    [\"core\", \"semantic\"]\n)\n</code></pre>"},{"location":"advanced/backup-restore/#database-recovery","title":"Database Recovery","text":"<pre><code>def recover_database_only(backup_path):\n    \"\"\"Recover only database without memory processing\"\"\"\n\n    dump_file = f\"{backup_path}/database/mirix_dump.sql\"\n\n    if os.path.exists(dump_file):\n        # Restore database\n        os.system(f\"psql -U $(whoami) -d mirix &lt; {dump_file}\")\n        print(\"Database restored from dump\")\n    else:\n        print(\"No database dump found in backup\")\n</code></pre>"},{"location":"advanced/backup-restore/#best-practices","title":"Best Practices","text":""},{"location":"advanced/backup-restore/#backup-strategy","title":"Backup Strategy","text":"<ol> <li>Regular Backups: Create automated daily backups</li> <li>Multiple Locations: Store backups in different locations</li> <li>Version Control: Keep multiple backup versions</li> <li>Verification: Always verify backup integrity</li> <li>Testing: Regularly test restore procedures</li> </ol>"},{"location":"advanced/backup-restore/#backup-frequency-recommendations","title":"Backup Frequency Recommendations","text":"Usage Pattern Backup Frequency Retention Light usage (&lt; 100 screenshots/day) Weekly 4 weeks Medium usage (100-500 screenshots/day) Daily 2 weeks Heavy usage (&gt; 500 screenshots/day) Twice daily 1 week Critical workflows After each session 30 days"},{"location":"advanced/backup-restore/#security-considerations","title":"Security Considerations","text":"<pre><code># Secure backup practices\ndef create_secure_backup(agent, backup_path, encryption_key=None):\n    \"\"\"Create encrypted backup\"\"\"\n\n    # Create backup\n    result = agent.save_agent(backup_path, sanitize_sensitive=True)\n\n    if encryption_key and result['success']:\n        # Encrypt sensitive files\n        encrypt_backup_files(backup_path, encryption_key)\n\n        # Remove unencrypted sensitive data\n        remove_plaintext_sensitive(backup_path)\n\n    return result\n</code></pre> <p>The backup and restore system ensures your MIRIX memories and configurations are always safe and portable across different systems and installations.</p>"},{"location":"advanced/backup-restore/#whats-next","title":"What's Next?","text":"<p>Learn about performance optimization:</p> <p>Performance \u2192</p> <p>Or explore the complete API reference:</p> <p>API Reference \u2192 </p>"},{"location":"advanced/performance/","title":"Performance","text":"<p>MIRIX delivers exceptional performance through intelligent memory consolidation, optimized search algorithms, and efficient data processing.</p>"},{"location":"advanced/performance/#evaluation-results","title":"Evaluation Results","text":""},{"location":"advanced/performance/#dataset-1-short-session-15-hours-700-images","title":"Dataset 1: Short Session (1.5 hours, 700 images)","text":"<p>Performance comparison on a focused 1.5-hour session with 700 screenshots:</p> Model Accuracy Notes Gemini 0.0833 (1/12) Direct API calls without context Letta Not Applicable Text-only system Letta-MultiModal Under Development - Mem0 Not Applicable Limited memory structure MIRIX-2025-04-08 0.4167 (5/12) First optimized version MIRIX-2025-04-20 0.5000 (6/12) Improved multi-agent coordination"},{"location":"advanced/performance/#dataset-2-extended-session-24-hours-5886-images","title":"Dataset 2: Extended Session (24 hours, 5,886 images)","text":"<p>Performance on a comprehensive 24-hour monitoring session:</p> Model Accuracy \u2191 Storage Size (MB) \u2193 Gemini 0.00 (0/16) 23,091.67 MIRIX-2025-04-27 0.5000 (8/16) 20.57 <p>Key Insights: - 1000x+ storage efficiency compared to raw storage - Infinite improvement in accuracy over baseline approaches - Sub-100MB storage for full-day monitoring</p>"},{"location":"advanced/performance/#performance-architecture","title":"Performance Architecture","text":""},{"location":"advanced/performance/#multi-agent-efficiency","title":"Multi-Agent Efficiency","text":"<pre><code>graph TB\n    A[Input Stream] --&gt; B[Meta Agent&lt;br/&gt;Coordinator]\n    B --&gt; C[Parallel Processing]\n\n    subgraph \"Memory Agents\"\n        D[Core Memory&lt;br/&gt;~10ms]\n        E[Episodic Memory&lt;br/&gt;~20ms]\n        F[Semantic Memory&lt;br/&gt;~30ms]\n        G[Procedural Memory&lt;br/&gt;~25ms]\n        H[Resource Memory&lt;br/&gt;~40ms]\n        I[Knowledge Vault&lt;br/&gt;~15ms]\n    end\n\n    C --&gt; D\n    C --&gt; E\n    C --&gt; F\n    C --&gt; G\n    C --&gt; H\n    C --&gt; I\n\n    D --&gt; J[Memory Consolidation&lt;br/&gt;~5ms]\n    E --&gt; J\n    F --&gt; J\n    G --&gt; J\n    H --&gt; J\n    I --&gt; J\n\n    J --&gt; K[Response Generation&lt;br/&gt;~50ms total]</code></pre>"},{"location":"advanced/performance/#processing-pipeline-performance","title":"Processing Pipeline Performance","text":"Stage Average Time Throughput Screenshot Capture ~1ms 1 FPS Cloud Upload ~100ms 10 images/sec Agent Processing ~200ms 5 batches/sec Memory Storage ~50ms 20 updates/sec Search Query ~15ms 65 queries/sec"},{"location":"advanced/performance/#search-performance","title":"Search Performance","text":""},{"location":"advanced/performance/#postgresql-bm25-benchmarks","title":"PostgreSQL BM25 Benchmarks","text":"<pre><code>xychart-beta\n    title \"Search Response Time by Dataset Size\"\n    x-axis [\"1K entries\", \"10K entries\", \"100K entries\", \"1M entries\"]\n    y-axis \"Response Time (ms)\" 0 --&gt; 100\n    bar [2, 5, 15, 45]</code></pre> <p>Performance Characteristics: - Sub-millisecond search on small datasets (&lt; 1K entries) - Linear scaling with dataset size - 50-100x faster than in-memory processing - Memory efficient with constant RAM usage regardless of dataset size</p>"},{"location":"advanced/performance/#search-method-comparison","title":"Search Method Comparison","text":"Method 10K Entries 100K Entries Memory Usage Best For PostgreSQL BM25 5ms 15ms 50MB Production use Vector Embedding 25ms 250ms 200MB Semantic similarity String Match 1ms 10ms 10MB Exact matching Fuzzy Match 15ms 150ms 75MB Typo tolerance"},{"location":"advanced/performance/#memory-optimization","title":"Memory Optimization","text":""},{"location":"advanced/performance/#storage-efficiency","title":"Storage Efficiency","text":"<pre><code># Storage compression example\noriginal_size = 23091.67  # MB (raw images)\nmirix_size = 20.57       # MB (processed memories)\ncompression_ratio = original_size / mirix_size\nprint(f\"Compression ratio: {compression_ratio:.0f}x\")  # ~1123x\n</code></pre>"},{"location":"advanced/performance/#memory-component-efficiency","title":"Memory Component Efficiency","text":"Memory Type Avg Size per Entry Compression Search Speed Core Memory 50 bytes N/A (always loaded) Instant Episodic Memory 200 bytes 5:1 2ms Semantic Memory 300 bytes 3:1 5ms Procedural Memory 400 bytes 4:1 8ms Resource Memory 1KB 10:1 12ms Knowledge Vault 100 bytes High encryption overhead 3ms"},{"location":"advanced/performance/#real-time-performance","title":"Real-Time Performance","text":""},{"location":"advanced/performance/#screenshot-processing-pipeline","title":"Screenshot Processing Pipeline","text":"<pre><code># Performance monitoring\nclass PerformanceMonitor:\n    def __init__(self):\n        self.metrics = {\n            \"screenshot_capture\": [],\n            \"cloud_upload\": [],\n            \"agent_processing\": [],\n            \"memory_storage\": [],\n            \"search_queries\": []\n        }\n\n    def record_metric(self, operation, duration_ms):\n        self.metrics[operation].append(duration_ms)\n\n    def get_stats(self, operation):\n        data = self.metrics[operation]\n        return {\n            \"avg\": sum(data) / len(data),\n            \"min\": min(data),\n            \"max\": max(data),\n            \"p95\": sorted(data)[int(len(data) * 0.95)]\n        }\n\n# Usage\nmonitor = PerformanceMonitor()\n\n# During processing\nstart = time.time()\nprocess_screenshot(image)\nmonitor.record_metric(\"agent_processing\", (time.time() - start) * 1000)\n</code></pre>"},{"location":"advanced/performance/#throughput-metrics","title":"Throughput Metrics","text":"Operation Peak Throughput Sustained Throughput Bottleneck Screenshot Capture 5 FPS 1 FPS Display refresh Image Upload 50 images/sec 10 images/sec Network bandwidth Memory Processing 100 updates/sec 20 updates/sec LLM API limits Database Writes 1000 ops/sec 500 ops/sec Disk I/O Search Queries 200 queries/sec 65 queries/sec CPU"},{"location":"advanced/performance/#optimization-strategies","title":"Optimization Strategies","text":""},{"location":"advanced/performance/#database-optimization","title":"Database Optimization","text":"<pre><code>-- Performance-critical indexes\nCREATE INDEX CONCURRENTLY idx_episodic_timestamp \nON episodic_memory (timestamp DESC);\n\nCREATE INDEX CONCURRENTLY idx_semantic_search_vector \nON semantic_memory USING GIN (search_vector);\n\nCREATE INDEX CONCURRENTLY idx_resource_content_search \nON resource_memory USING GIN (to_tsvector('english', content));\n\n-- Analyze query performance\nEXPLAIN (ANALYZE, BUFFERS) \nSELECT * FROM semantic_memory \nWHERE search_vector @@ plainto_tsquery('machine learning')\nORDER BY ts_rank_cd(search_vector, plainto_tsquery('machine learning'), 32) DESC\nLIMIT 50;\n</code></pre>"},{"location":"advanced/performance/#agent-processing-optimization","title":"Agent Processing Optimization","text":"<pre><code># Batch processing for efficiency\nclass BatchProcessor:\n    def __init__(self, batch_size=20, timeout=300):\n        self.batch_size = batch_size\n        self.timeout = timeout\n        self.batch = []\n        self.last_process = time.time()\n\n    def add_item(self, item, force_process=False):\n        self.batch.append(item)\n\n        should_process = (\n            len(self.batch) &gt;= self.batch_size or\n            time.time() - self.last_process &gt; self.timeout or\n            force_process\n        )\n\n        if should_process:\n            self.process_batch()\n\n    def process_batch(self):\n        if not self.batch:\n            return\n\n        # Process all items in one agent call\n        start_time = time.time()\n        agent.process_batch(self.batch)\n        processing_time = time.time() - start_time\n\n        print(f\"Processed {len(self.batch)} items in {processing_time:.2f}s\")\n\n        self.batch = []\n        self.last_process = time.time()\n\n# Usage\nprocessor = BatchProcessor()\nprocessor.add_item(screenshot_data, force_process=False)\n</code></pre>"},{"location":"advanced/performance/#memory-management-optimization","title":"Memory Management Optimization","text":"<pre><code># Intelligent memory cleanup\ndef optimize_memories():\n    \"\"\"Optimize memory storage for performance\"\"\"\n\n    # Archive old episodic memories\n    old_episodes = get_old_episodic_memories(days=30)\n    archive_memories(old_episodes, compression=True)\n\n    # Merge duplicate semantic entries\n    duplicates = find_semantic_duplicates(similarity_threshold=0.95)\n    merge_semantic_memories(duplicates)\n\n    # Compress large resource memories\n    large_resources = get_large_resource_memories(size_mb=1)\n    compress_resource_content(large_resources)\n\n    # Update memory statistics\n    update_memory_statistics()\n\n    # Rebuild search indexes if needed\n    if should_rebuild_indexes():\n        rebuild_search_indexes()\n\n# Schedule optimization\nschedule.every().week.do(optimize_memories)\n</code></pre>"},{"location":"advanced/performance/#performance-monitoring","title":"Performance Monitoring","text":""},{"location":"advanced/performance/#real-time-metrics-dashboard","title":"Real-Time Metrics Dashboard","text":"<pre><code>def get_performance_dashboard():\n    \"\"\"Get current performance metrics\"\"\"\n    return {\n        \"system\": {\n            \"cpu_usage\": psutil.cpu_percent(),\n            \"memory_usage\": psutil.virtual_memory().percent,\n            \"disk_io\": psutil.disk_io_counters(),\n            \"network_io\": psutil.net_io_counters()\n        },\n        \"mirix\": {\n            \"screenshots_per_hour\": get_screenshot_rate(),\n            \"avg_processing_time\": get_avg_processing_time(),\n            \"memory_growth_rate\": get_memory_growth_rate(),\n            \"search_response_time\": get_avg_search_time(),\n            \"database_size\": get_database_size(),\n            \"active_agents\": get_active_agent_count()\n        },\n        \"database\": {\n            \"connection_count\": get_db_connections(),\n            \"cache_hit_ratio\": get_cache_hit_ratio(),\n            \"index_usage\": get_index_usage_stats(),\n            \"slow_queries\": get_slow_query_count()\n        }\n    }\n\n# Usage\ndashboard = get_performance_dashboard()\nprint(f\"System CPU: {dashboard['system']['cpu_usage']}%\")\nprint(f\"Avg search time: {dashboard['mirix']['search_response_time']}ms\")\n</code></pre>"},{"location":"advanced/performance/#performance-alerts","title":"Performance Alerts","text":"<pre><code>def check_performance_alerts():\n    \"\"\"Monitor for performance issues\"\"\"\n    alerts = []\n\n    dashboard = get_performance_dashboard()\n\n    # High CPU usage\n    if dashboard['system']['cpu_usage'] &gt; 80:\n        alerts.append(\"High CPU usage detected\")\n\n    # Slow search performance\n    if dashboard['mirix']['search_response_time'] &gt; 100:\n        alerts.append(\"Search queries are slow\")\n\n    # Database growth\n    if dashboard['mirix']['database_size'] &gt; 1000:\n        alerts.append(\"Database size exceeding 1GB\")\n\n    # Memory leak detection\n    if dashboard['system']['memory_usage'] &gt; 90:\n        alerts.append(\"High memory usage - possible leak\")\n\n    return alerts\n\n# Monitor alerts\nalerts = check_performance_alerts()\nfor alert in alerts:\n    print(f\"\u26a0\ufe0f  {alert}\")\n</code></pre>"},{"location":"advanced/performance/#performance-tuning-guide","title":"Performance Tuning Guide","text":""},{"location":"advanced/performance/#system-level-optimizations","title":"System-Level Optimizations","text":""},{"location":"advanced/performance/#postgresql-configuration","title":"PostgreSQL Configuration","text":"<pre><code>-- postgresql.conf optimizations\nshared_buffers = 256MB                    -- 25% of RAM\neffective_cache_size = 1GB               -- 75% of RAM\nwork_mem = 4MB                           -- For complex queries\nmaintenance_work_mem = 64MB              -- For maintenance operations\ncheckpoint_completion_target = 0.9       -- Spread checkpoints\nwal_buffers = 16MB                       -- WAL buffer size\n</code></pre>"},{"location":"advanced/performance/#python-performance","title":"Python Performance","text":"<pre><code># Optimize Python runtime\nimport gc\nimport threading\n\n# Garbage collection tuning\ngc.set_threshold(700, 10, 10)  # More aggressive GC\n\n# Thread pool optimization\nfrom concurrent.futures import ThreadPoolExecutor\n\nexecutor = ThreadPoolExecutor(\n    max_workers=min(32, (os.cpu_count() or 1) + 4),\n    thread_name_prefix=\"mirix_worker\"\n)\n</code></pre>"},{"location":"advanced/performance/#application-level-tuning","title":"Application-Level Tuning","text":""},{"location":"advanced/performance/#configuration-optimization","title":"Configuration Optimization","text":"<pre><code># mirix.yaml performance settings\nperformance:\n  batch_processing:\n    enabled: true\n    batch_size: 20\n    timeout_seconds: 300\n\n  search:\n    cache_enabled: true\n    cache_size: 1000\n    cache_ttl: 3600\n\n  database:\n    connection_pool_size: 10\n    max_overflow: 20\n    pool_timeout: 30\n\n  memory_management:\n    auto_cleanup: true\n    cleanup_interval_hours: 24\n    max_memory_size_mb: 1000\n</code></pre>"},{"location":"advanced/performance/#memory-tuning","title":"Memory Tuning","text":"<pre><code># Memory usage optimization\ndef optimize_memory_usage():\n    \"\"\"Optimize memory usage\"\"\"\n\n    # Enable compression for large memories\n    enable_memory_compression(threshold_mb=10)\n\n    # Use memory mapping for large resources\n    enable_memory_mapping(resource_size_mb=5)\n\n    # Optimize search indexes\n    optimize_search_indexes()\n\n    # Set memory limits\n    set_memory_limits(max_mb=500)\n</code></pre>"},{"location":"advanced/performance/#scalability-considerations","title":"Scalability Considerations","text":""},{"location":"advanced/performance/#horizontal-scaling","title":"Horizontal Scaling","text":"<pre><code># Multi-instance deployment\nclass MIRIXCluster:\n    def __init__(self, nodes):\n        self.nodes = nodes\n        self.load_balancer = LoadBalancer(nodes)\n\n    def process_request(self, request):\n        # Route to least loaded node\n        node = self.load_balancer.get_optimal_node()\n        return node.process(request)\n\n    def sync_memories(self):\n        # Synchronize memories across nodes\n        for node in self.nodes:\n            node.sync_with_cluster()\n</code></pre>"},{"location":"advanced/performance/#vertical-scaling-limits","title":"Vertical Scaling Limits","text":"Resource Minimum Recommended Maximum Tested RAM 4GB 8GB 32GB CPU Cores 2 4 16 Storage 10GB 50GB 500GB Screenshots/day 1,000 10,000 100,000"},{"location":"advanced/performance/#performance-best-practices","title":"Performance Best Practices","text":""},{"location":"advanced/performance/#development-guidelines","title":"Development Guidelines","text":"<ol> <li>Batch Operations: Process multiple items together when possible</li> <li>Lazy Loading: Load memories only when needed</li> <li>Caching Strategy: Cache frequently accessed data</li> <li>Index Optimization: Ensure proper database indexes</li> <li>Resource Cleanup: Regular cleanup of old data</li> </ol>"},{"location":"advanced/performance/#monitoring-best-practices","title":"Monitoring Best Practices","text":"<ol> <li>Continuous Monitoring: Track key metrics continuously</li> <li>Performance Baselines: Establish performance baselines</li> <li>Alert Thresholds: Set appropriate alert thresholds</li> <li>Regular Profiling: Profile code regularly for bottlenecks</li> <li>Capacity Planning: Plan for growth in advance</li> </ol>"},{"location":"advanced/performance/#optimization-checklist","title":"Optimization Checklist","text":"<ul> <li>[ ] PostgreSQL properly configured and indexed</li> <li>[ ] Batch processing enabled for agent operations</li> <li>[ ] Search caching configured</li> <li>[ ] Memory cleanup scheduled</li> <li>[ ] Performance monitoring active</li> <li>[ ] Database maintenance scheduled</li> <li>[ ] Resource limits configured</li> <li>[ ] Backup strategy optimized</li> </ul> <p>The performance optimizations ensure MIRIX can handle large-scale personal monitoring while maintaining responsive interactions and efficient resource usage.</p>"},{"location":"advanced/performance/#whats-next","title":"What's Next?","text":"<p>Return to explore other advanced features:</p> <p>Security &amp; Privacy \u2192 Backup &amp; Restore \u2192 </p>"},{"location":"advanced/security-privacy/","title":"Security &amp; Privacy","text":"<p>MIRIX is designed with privacy and security as core principles. All sensitive data processing happens locally, with user-controlled privacy settings and enterprise-grade security practices.</p>"},{"location":"advanced/security-privacy/#privacy-architecture","title":"Privacy Architecture","text":""},{"location":"advanced/security-privacy/#data-flow-overview","title":"Data Flow Overview","text":"<pre><code>graph TB\n    A[Screen Capture] --&gt; B[Temporary Cloud Storage&lt;br/&gt;Your Google Cloud]\n    B --&gt; C[Local Processing&lt;br/&gt;MIRIX Agents]\n    C --&gt; D[Local Database&lt;br/&gt;PostgreSQL/SQLite]\n\n    B --&gt; E[Auto-Delete&lt;br/&gt;After Processing]\n\n    F[User Queries] --&gt; C\n    C --&gt; G[Local Responses]\n\n    H[Backup Data] --&gt; I[Local Storage Only]\n\n    style B fill:#ffcccc\n    style D fill:#ccffcc\n    style I fill:#ccffcc\n\n    classDef cloud fill:#ffcccc,stroke:#ff6666\n    classDef local fill:#ccffcc,stroke:#66cc66\n\n    class B cloud\n    class D,I local</code></pre>"},{"location":"advanced/security-privacy/#privacy-principles","title":"Privacy Principles","text":"<ol> <li>Local Data Storage: All long-term user data remains on your local machine</li> <li>User-Controlled Cloud: Only your personal Google Cloud account is used for temporary storage</li> <li>Automatic Cleanup: Screenshots are automatically deleted after processing</li> <li>No Third-Party Sharing: Your data never leaves your control</li> <li>Transparent Processing: All data processing is documented and auditable</li> </ol>"},{"location":"advanced/security-privacy/#screenshot-handling","title":"Screenshot Handling","text":""},{"location":"advanced/security-privacy/#capture-process","title":"Capture Process","text":"<pre><code># MIRIX screenshot workflow\ndef screenshot_workflow():\n    # 1. Capture screenshot every second\n    screenshot = capture_screen()\n\n    # 2. Upload to YOUR Google Cloud storage\n    upload_to_user_cloud(screenshot, user_bucket)\n\n    # 3. Keep only recent 600 screenshots (~10 minutes)\n    maintain_recent_screenshots(limit=600)\n\n    # 4. Process screenshots through agents\n    process_with_agents(screenshot)\n\n    # 5. Delete processed screenshots\n    delete_processed_screenshots()\n</code></pre>"},{"location":"advanced/security-privacy/#privacy-controls","title":"Privacy Controls","text":""},{"location":"advanced/security-privacy/#screenshot-exclusions","title":"Screenshot Exclusions","text":"<pre><code># Configure applications to exclude from capture\nexcluded_apps = [\n    \"Banking App\",\n    \"Password Manager\", \n    \"Private Browser\",\n    \"Secure Messaging\"\n]\n\n# Exclude specific window titles\nexcluded_titles = [\n    \"*password*\",\n    \"*private*\",\n    \"*incognito*\"\n]\n</code></pre>"},{"location":"advanced/security-privacy/#time-based-controls","title":"Time-Based Controls","text":"<pre><code># Disable capture during specific hours\nprivacy_schedule = {\n    \"disable_hours\": \"22:00-06:00\",  # No capture at night\n    \"disable_days\": [\"Saturday\", \"Sunday\"],  # Weekend privacy\n    \"break_intervals\": 30  # 30-minute break every 2 hours\n}\n</code></pre>"},{"location":"advanced/security-privacy/#local-data-storage","title":"Local Data Storage","text":""},{"location":"advanced/security-privacy/#database-security","title":"Database Security","text":""},{"location":"advanced/security-privacy/#postgresql-security","title":"PostgreSQL Security","text":"<pre><code>-- Enable row-level security\nALTER TABLE memory_table ENABLE ROW LEVEL SECURITY;\n\n-- Create security policies\nCREATE POLICY user_memory_policy ON memory_table\n    USING (user_id = current_user_id());\n\n-- Encrypt sensitive columns\nCREATE EXTENSION IF NOT EXISTS pgcrypto;\n</code></pre>"},{"location":"advanced/security-privacy/#sqlite-security","title":"SQLite Security","text":"<pre><code># Enable encryption for SQLite\nimport sqlite3\nfrom pysqlcipher3 import dbapi2 as sqlite\n\n# Encrypted database connection\nconn = sqlite.connect(\"mirix.db\")\nconn.execute(\"PRAGMA key='your_encryption_key'\")\n</code></pre>"},{"location":"advanced/security-privacy/#file-system-security","title":"File System Security","text":"<pre><code># Secure file permissions\nimport os\nimport stat\n\ndef secure_file_permissions(file_path):\n    # Set read/write for owner only\n    os.chmod(file_path, stat.S_IRUSR | stat.S_IWUSR)\n\n# Apply to all MIRIX files\nsecure_directories = [\n    \"~/.mirix/\",\n    \"~/.mirix/backups/\",\n    \"~/.mirix/logs/\"\n]\n</code></pre>"},{"location":"advanced/security-privacy/#memory-component-security","title":"Memory Component Security","text":""},{"location":"advanced/security-privacy/#knowledge-vault-security","title":"Knowledge Vault Security","text":"<p>The Knowledge Vault handles sensitive information with special security measures:</p>"},{"location":"advanced/security-privacy/#sensitivity-classification","title":"Sensitivity Classification","text":"<pre><code>sensitivity_levels = {\n    \"low\": {\n        \"encryption\": False,\n        \"access_logging\": False,\n        \"examples\": [\"bookmarks\", \"public notes\"]\n    },\n    \"medium\": {\n        \"encryption\": True,\n        \"access_logging\": True,\n        \"examples\": [\"contact info\", \"work documents\"]\n    },\n    \"high\": {\n        \"encryption\": True,\n        \"access_logging\": True,\n        \"access_control\": True,\n        \"examples\": [\"passwords\", \"API keys\", \"financial data\"]\n    }\n}\n</code></pre>"},{"location":"advanced/security-privacy/#secure-storage","title":"Secure Storage","text":"<pre><code># High-sensitivity data handling\ndef store_sensitive_data(data, sensitivity=\"high\"):\n    if sensitivity == \"high\":\n        # Encrypt data\n        encrypted_data = encrypt_with_user_key(data)\n\n        # Log access\n        log_access_attempt(data_type=\"sensitive\", action=\"store\")\n\n        # Store with restricted access\n        store_with_permissions(encrypted_data, permissions=\"user_only\")\n\n    return data_id\n</code></pre>"},{"location":"advanced/security-privacy/#access-control","title":"Access Control","text":"<pre><code>class SecureMemoryAccess:\n    def __init__(self, user_id, session_key):\n        self.user_id = user_id\n        self.session_key = session_key\n        self.access_log = []\n\n    def access_memory(self, memory_id, memory_type):\n        # Verify user permissions\n        if not self.verify_access(memory_id, memory_type):\n            raise PermissionError(\"Access denied\")\n\n        # Log access\n        self.log_access(memory_id, memory_type)\n\n        # Return data based on sensitivity\n        return self.get_filtered_data(memory_id, memory_type)\n</code></pre>"},{"location":"advanced/security-privacy/#cloud-storage-security","title":"Cloud Storage Security","text":""},{"location":"advanced/security-privacy/#google-cloud-configuration","title":"Google Cloud Configuration","text":"<pre><code># Secure cloud storage configuration\ngoogle_cloud:\n  project_id: \"your-personal-project\"\n  bucket_name: \"mirix-screenshots-private\"\n  location: \"us-central1\"\n\n  security:\n    encryption: \"GOOGLE_MANAGED\"  # Or customer-managed keys\n    access_control: \"PRIVATE\"\n    lifecycle_rules:\n      - delete_after_hours: 24\n      - archive_after_minutes: 60\n</code></pre>"},{"location":"advanced/security-privacy/#authentication-security","title":"Authentication Security","text":"<pre><code># Secure authentication setup\ndef setup_secure_auth():\n    # Use service account with minimal permissions\n    credentials = service_account.Credentials.from_service_account_info({\n        \"type\": \"service_account\",\n        \"project_id\": \"your-project\",\n        \"private_key_id\": \"key-id\",\n        \"private_key\": \"-----BEGIN PRIVATE KEY-----\\n...\",\n        \"client_email\": \"mirix@your-project.iam.gserviceaccount.com\",\n        \"client_id\": \"client-id\",\n        \"auth_uri\": \"https://accounts.google.com/o/oauth2/auth\",\n        \"token_uri\": \"https://oauth2.googleapis.com/token\"\n    })\n\n    # Scope to storage only\n    scoped_credentials = credentials.with_scopes([\n        \"https://www.googleapis.com/auth/cloud-platform\"\n    ])\n\n    return scoped_credentials\n</code></pre>"},{"location":"advanced/security-privacy/#network-security","title":"Network Security","text":""},{"location":"advanced/security-privacy/#api-communication","title":"API Communication","text":"<pre><code># Secure API calls\nimport requests\nimport ssl\n\ndef secure_api_call(url, data, api_key):\n    # Create secure SSL context\n    ssl_context = ssl.create_default_context()\n    ssl_context.check_hostname = True\n    ssl_context.verify_mode = ssl.CERT_REQUIRED\n\n    # Secure headers\n    headers = {\n        \"Authorization\": f\"Bearer {api_key}\",\n        \"Content-Type\": \"application/json\",\n        \"User-Agent\": \"MIRIX/1.0\"\n    }\n\n    # Make request with security\n    response = requests.post(\n        url,\n        json=data,\n        headers=headers,\n        verify=True,  # Verify SSL certificates\n        timeout=30\n    )\n\n    return response\n</code></pre>"},{"location":"advanced/security-privacy/#local-network-protection","title":"Local Network Protection","text":"<pre><code># Disable unnecessary network services\ndef secure_network_config():\n    config = {\n        \"disable_telemetry\": True,\n        \"disable_auto_updates\": False,  # Keep security updates\n        \"local_only_api\": True,\n        \"require_authentication\": True,\n        \"rate_limiting\": {\n            \"max_requests_per_minute\": 60,\n            \"max_requests_per_hour\": 1000\n        }\n    }\n    return config\n</code></pre>"},{"location":"advanced/security-privacy/#audit-and-monitoring","title":"Audit and Monitoring","text":""},{"location":"advanced/security-privacy/#security-logging","title":"Security Logging","text":"<pre><code>import logging\nfrom datetime import datetime\n\n# Security audit logger\nsecurity_logger = logging.getLogger('mirix.security')\nsecurity_logger.setLevel(logging.INFO)\n\ndef log_security_event(event_type, details, severity=\"INFO\"):\n    log_entry = {\n        \"timestamp\": datetime.utcnow().isoformat(),\n        \"event_type\": event_type,\n        \"details\": details,\n        \"severity\": severity,\n        \"user_id\": get_current_user_id(),\n        \"session_id\": get_current_session_id()\n    }\n\n    security_logger.info(f\"SECURITY_EVENT: {log_entry}\")\n\n# Usage examples\nlog_security_event(\"MEMORY_ACCESS\", \"Accessed Knowledge Vault\", \"INFO\")\nlog_security_event(\"FAILED_LOGIN\", \"Invalid credentials\", \"WARNING\")\nlog_security_event(\"DATA_EXPORT\", \"Backup created\", \"INFO\")\n</code></pre>"},{"location":"advanced/security-privacy/#privacy-monitoring","title":"Privacy Monitoring","text":"<pre><code>def privacy_health_check():\n    \"\"\"Monitor privacy compliance\"\"\"\n    issues = []\n\n    # Check screenshot retention\n    screenshot_count = count_stored_screenshots()\n    if screenshot_count &gt; 600:\n        issues.append(\"Too many screenshots stored\")\n\n    # Check data encryption\n    unencrypted_sensitive = find_unencrypted_sensitive_data()\n    if unencrypted_sensitive:\n        issues.append(f\"Found {len(unencrypted_sensitive)} unencrypted sensitive items\")\n\n    # Check cloud storage\n    cloud_retention = check_cloud_retention_policy()\n    if not cloud_retention:\n        issues.append(\"Cloud retention policy not configured\")\n\n    return issues\n</code></pre>"},{"location":"advanced/security-privacy/#compliance-and-standards","title":"Compliance and Standards","text":""},{"location":"advanced/security-privacy/#data-protection-compliance","title":"Data Protection Compliance","text":"<p>MIRIX follows privacy regulations including:</p> <ul> <li>GDPR (General Data Protection Regulation)</li> <li>Right to be forgotten (data deletion)</li> <li>Data portability (backup/export)</li> <li> <p>Privacy by design (local processing)</p> </li> <li> <p>CCPA (California Consumer Privacy Act)</p> </li> <li>Transparent data collection</li> <li>User control over data</li> <li> <p>Secure data handling</p> </li> <li> <p>SOC 2 Type II Principles</p> </li> <li>Security controls</li> <li>Availability monitoring</li> <li>Processing integrity</li> <li>Confidentiality measures</li> </ul>"},{"location":"advanced/security-privacy/#security-best-practices","title":"Security Best Practices","text":""},{"location":"advanced/security-privacy/#data-minimization","title":"Data Minimization","text":"<pre><code>def data_minimization_policy():\n    \"\"\"Implement data minimization\"\"\"\n    policies = {\n        \"collect_only_necessary\": True,\n        \"delete_after_processing\": True,\n        \"compress_old_data\": True,\n        \"anonymize_when_possible\": True\n    }\n    return policies\n</code></pre>"},{"location":"advanced/security-privacy/#encryption-standards","title":"Encryption Standards","text":"<pre><code># Use industry-standard encryption\nfrom cryptography.fernet import Fernet\nimport hashlib\n\ndef secure_encryption():\n    # Generate key from user password\n    def generate_key(password: str) -&gt; bytes:\n        return hashlib.sha256(password.encode()).digest()\n\n    # Encrypt sensitive data\n    def encrypt_data(data: str, key: bytes) -&gt; str:\n        f = Fernet(key)\n        return f.encrypt(data.encode()).decode()\n\n    # Decrypt sensitive data\n    def decrypt_data(encrypted_data: str, key: bytes) -&gt; str:\n        f = Fernet(key)\n        return f.decrypt(encrypted_data.encode()).decode()\n</code></pre>"},{"location":"advanced/security-privacy/#user-privacy-controls","title":"User Privacy Controls","text":""},{"location":"advanced/security-privacy/#configuration-options","title":"Configuration Options","text":"<pre><code># Privacy configuration in mirix.yaml\nprivacy:\n  screenshot_capture:\n    enabled: true\n    excluded_apps: \n      - \"Banking App\"\n      - \"Password Manager\"\n    excluded_windows:\n      - \"*password*\"\n      - \"*private*\"\n\n  data_retention:\n    screenshot_hours: 24\n    memory_days: 365\n    log_days: 30\n\n  cloud_storage:\n    enabled: true\n    auto_delete: true\n    encryption: \"google_managed\"\n\n  memory_security:\n    encrypt_sensitive: true\n    require_auth: true\n    audit_access: true\n</code></pre>"},{"location":"advanced/security-privacy/#privacy-dashboard","title":"Privacy Dashboard","text":"<pre><code>def privacy_dashboard():\n    \"\"\"Show privacy status to user\"\"\"\n    dashboard = {\n        \"screenshots_stored\": count_screenshots(),\n        \"cloud_storage_usage\": get_cloud_usage(),\n        \"sensitive_data_count\": count_sensitive_data(),\n        \"last_cleanup\": get_last_cleanup_time(),\n        \"encryption_status\": check_encryption_status(),\n        \"privacy_score\": calculate_privacy_score()\n    }\n    return dashboard\n</code></pre>"},{"location":"advanced/security-privacy/#incident-response","title":"Incident Response","text":""},{"location":"advanced/security-privacy/#security-incident-handling","title":"Security Incident Handling","text":"<pre><code>def handle_security_incident(incident_type, details):\n    \"\"\"Handle security incidents\"\"\"\n\n    # Immediate response\n    if incident_type == \"UNAUTHORIZED_ACCESS\":\n        # Lock down sensitive data\n        lock_sensitive_data()\n        # Notify user\n        send_security_alert(details)\n        # Log incident\n        log_security_incident(incident_type, details)\n\n    elif incident_type == \"DATA_BREACH\":\n        # Stop all processing\n        stop_all_agents()\n        # Secure data\n        encrypt_all_data()\n        # Create incident report\n        create_incident_report(details)\n\n    elif incident_type == \"CLOUD_COMPROMISE\":\n        # Disable cloud access\n        disable_cloud_access()\n        # Switch to local-only mode\n        enable_local_only_mode()\n        # Notify user\n        send_urgent_alert(details)\n</code></pre>"},{"location":"advanced/security-privacy/#recovery-procedures","title":"Recovery Procedures","text":"<pre><code>def security_recovery_checklist():\n    \"\"\"Security recovery checklist\"\"\"\n    checklist = [\n        \"Change all API keys and passwords\",\n        \"Rotate encryption keys\",\n        \"Audit all access logs\",\n        \"Verify data integrity\",\n        \"Update security configurations\",\n        \"Test backup systems\",\n        \"Document lessons learned\"\n    ]\n    return checklist\n</code></pre>"},{"location":"advanced/security-privacy/#security-updates","title":"Security Updates","text":""},{"location":"advanced/security-privacy/#automatic-security-updates","title":"Automatic Security Updates","text":"<pre><code>def security_update_system():\n    \"\"\"Handle security updates\"\"\"\n\n    # Check for security updates\n    updates = check_security_updates()\n\n    for update in updates:\n        if update.priority == \"CRITICAL\":\n            # Auto-install critical security updates\n            install_update(update)\n            log_security_event(\"SECURITY_UPDATE\", f\"Installed {update.name}\")\n\n        elif update.priority == \"HIGH\":\n            # Notify user of important updates\n            notify_user_update(update)\n</code></pre> <p>By following these security and privacy practices, MIRIX ensures that your personal data remains secure while providing the intelligent assistance you need.</p>"},{"location":"advanced/security-privacy/#whats-next","title":"What's Next?","text":"<p>Learn about performance optimization and system tuning:</p> <p>Performance \u2192</p> <p>Or explore backup and restore features:</p> <p>Backup &amp; Restore \u2192 </p>"},{"location":"api/agent-api/","title":"Agent API Reference","text":"<p>Complete API reference for the MIRIX <code>AgentWrapper</code> class and related functionality.</p>"},{"location":"api/agent-api/#agentwrapper-class","title":"AgentWrapper Class","text":"<p>The main interface for interacting with MIRIX agents.</p>"},{"location":"api/agent-api/#constructor","title":"Constructor","text":"<pre><code>AgentWrapper(config_path: str, load_from: str = None)\n</code></pre> <p>Initialize a new MIRIX agent.</p> <p>Parameters: - <code>config_path</code> (str): Path to the configuration YAML file - <code>load_from</code> (str, optional): Path to backup directory to restore from</p> <p>Example: <pre><code>from mirix.agent import AgentWrapper\n\n# Basic initialization\nagent = AgentWrapper(\"./configs/mirix.yaml\")\n\n# Initialize with backup restore\nagent = AgentWrapper(\"./configs/mirix.yaml\", load_from=\"./backup\")\n</code></pre></p>"},{"location":"api/agent-api/#core-methods","title":"Core Methods","text":""},{"location":"api/agent-api/#send_message","title":"send_message()","text":"<pre><code>send_message(\n    message: Union[str, List[Dict]], \n    image_uris: List[str] = None,\n    voice_files: List[str] = None, \n    force_absorb_content: bool = False\n) -&gt; str\n</code></pre> <p>Send a message to the agent for processing or conversation.</p> <p>Parameters: - <code>message</code>: Text message or multi-modal message structure - <code>image_uris</code>: List of local image file paths - <code>voice_files</code>: List of base64-encoded audio data - <code>force_absorb_content</code>: Whether to process immediately (True) or batch (False)</p> <p>Returns: - <code>str</code>: Agent's response</p> <p>Examples: <pre><code># Simple text message\nresponse = agent.send_message(\"What did I work on today?\")\n\n# Multi-modal message\nresponse = agent.send_message(\n    message=\"Working on documentation\",\n    image_uris=[\"/screenshots/vscode.png\"],\n    force_absorb_content=True\n)\n\n# Structured multi-modal\nresponse = agent.send_message(\n    message=[\n        {'type': 'text', 'text': \"Here's the design:\"},\n        {'type': 'image', 'image_url': \"data:image/png;base64,...\"}\n    ]\n)\n</code></pre></p>"},{"location":"api/agent-api/#search_memory","title":"search_memory()","text":"<pre><code>search_memory(\n    query: str,\n    memory_types: List[str] = None,\n    limit: int = 50,\n    search_method: str = \"bm25\"\n) -&gt; List[Dict]\n</code></pre> <p>Search across memory components.</p> <p>Parameters: - <code>query</code>: Search query string - <code>memory_types</code>: List of memory types to search (default: all) - <code>limit</code>: Maximum number of results - <code>search_method</code>: Search method (\"bm25\", \"embedding\", \"string_match\", \"fuzzy_match\")</p> <p>Returns: - <code>List[Dict]</code>: Search results with metadata</p> <p>Example: <pre><code># Search all memories\nresults = agent.search_memory(\"machine learning\")\n\n# Search specific memory types\nresults = agent.search_memory(\n    query=\"project documentation\",\n    memory_types=[\"resource\", \"procedural\"],\n    limit=20\n)\n</code></pre></p>"},{"location":"api/agent-api/#backup-and-restore","title":"Backup and Restore","text":""},{"location":"api/agent-api/#save_agent","title":"save_agent()","text":"<pre><code>save_agent(\n    backup_path: str,\n    include_logs: bool = False,\n    compress: bool = False,\n    verify_integrity: bool = False\n) -&gt; Dict\n</code></pre> <p>Create a backup of the agent state.</p> <p>Parameters: - <code>backup_path</code>: Directory to save backup - <code>include_logs</code>: Include log files in backup - <code>compress</code>: Compress backup files - <code>verify_integrity</code>: Verify backup after creation</p> <p>Returns: - <code>Dict</code>: Backup result with status and metadata</p> <p>Example: <pre><code>result = agent.save_agent(\n    \"./backup_20240315\",\n    include_logs=True,\n    verify_integrity=True\n)\n\nif result['success']:\n    print(f\"Backup created: {result['backup_path']}\")\n    print(f\"Size: {result['size_mb']} MB\")\n</code></pre></p>"},{"location":"api/agent-api/#load_agent","title":"load_agent()","text":"<pre><code>load_agent(\n    backup_path: str,\n    restore_components: Dict = None\n) -&gt; Dict\n</code></pre> <p>Restore agent state from backup.</p> <p>Parameters: - <code>backup_path</code>: Path to backup directory - <code>restore_components</code>: Dictionary specifying which components to restore</p> <p>Returns: - <code>Dict</code>: Restore result with status and statistics</p> <p>Example: <pre><code>result = agent.load_agent(\n    \"./backup_20240315\",\n    restore_components={\n        \"memories\": True,\n        \"conversations\": True,\n        \"config\": False\n    }\n)\n\nif result['success']:\n    print(f\"Restored {result['memory_count']} memories\")\n</code></pre></p>"},{"location":"api/agent-api/#utility-methods","title":"Utility Methods","text":""},{"location":"api/agent-api/#get_memory_statistics","title":"get_memory_statistics()","text":"<pre><code>get_memory_statistics() -&gt; Dict\n</code></pre> <p>Get statistics about stored memories.</p> <p>Returns: - <code>Dict</code>: Memory statistics including counts and sizes</p> <p>Example: <pre><code>stats = agent.get_memory_statistics()\nprint(f\"Total memories: {stats['total_count']}\")\nprint(f\"Database size: {stats['total_size_mb']} MB\")\n</code></pre></p>"},{"location":"api/agent-api/#get_agent_status","title":"get_agent_status()","text":"<pre><code>get_agent_status() -&gt; Dict\n</code></pre> <p>Get current agent status and health information.</p> <p>Returns: - <code>Dict</code>: Agent status including processing state and performance metrics</p> <p>Example: <pre><code>status = agent.get_agent_status()\nprint(f\"Agent state: {status['state']}\")\nprint(f\"Processing queue: {status['queue_length']} items\")\n</code></pre></p>"},{"location":"api/agent-api/#data-structures","title":"Data Structures","text":""},{"location":"api/agent-api/#message-structure","title":"Message Structure","text":"<p>For multi-modal messages:</p> <pre><code>message = [\n    {\n        'type': 'text',\n        'text': 'Your text content here'\n    },\n    {\n        'type': 'image', \n        'image_url': 'data:image/png;base64,iVBORw0KGgo...'\n    }\n]\n</code></pre>"},{"location":"api/agent-api/#search-result-structure","title":"Search Result Structure","text":"<pre><code>{\n    'id': 'memory_123',\n    'memory_type': 'semantic',\n    'content': 'Memory content...',\n    'metadata': {\n        'timestamp': '2024-03-15T10:30:00Z',\n        'source': 'user_interaction',\n        'confidence': 0.95\n    },\n    'score': 0.87\n}\n</code></pre>"},{"location":"api/agent-api/#backup-result-structure","title":"Backup Result Structure","text":"<pre><code>{\n    'success': True,\n    'message': 'Agent state saved successfully',\n    'backup_path': './backup_20240315',\n    'size_mb': 45.2,\n    'file_count': 12,\n    'verification_passed': True\n}\n</code></pre>"},{"location":"api/agent-api/#error-handling","title":"Error Handling","text":""},{"location":"api/agent-api/#common-exceptions","title":"Common Exceptions","text":"<pre><code>from mirix.exceptions import (\n    MIRIXConfigError,\n    MIRIXDatabaseError,\n    MIRIXBackupError,\n    MIRIXSearchError\n)\n\ntry:\n    agent = AgentWrapper(\"./configs/mirix.yaml\")\n    response = agent.send_message(\"Hello\")\nexcept MIRIXConfigError as e:\n    print(f\"Configuration error: {e}\")\nexcept MIRIXDatabaseError as e:\n    print(f\"Database error: {e}\")\nexcept Exception as e:\n    print(f\"Unexpected error: {e}\")\n</code></pre>"},{"location":"api/agent-api/#error-response-format","title":"Error Response Format","text":"<pre><code>{\n    'success': False,\n    'error': 'Error description',\n    'error_code': 'MIRIX_001',\n    'details': 'Additional error details'\n}\n</code></pre>"},{"location":"api/agent-api/#configuration","title":"Configuration","text":""},{"location":"api/agent-api/#agent-configuration-mirixyaml","title":"Agent Configuration (mirix.yaml)","text":"<pre><code>agent:\n  name: \"mirix_assistant\"\n  version: \"1.0.0\"\n\ndatabase:\n  type: \"postgresql\"  # or \"sqlite\"\n  connection_string: \"postgresql://user@localhost/mirix\"\n\nprocessing:\n  batch_size: 20\n  timeout_seconds: 300\n\nsearch:\n  default_method: \"bm25\"\n  default_limit: 50\n\nmemory:\n  auto_cleanup: true\n  max_size_mb: 1000\n</code></pre>"},{"location":"api/agent-api/#best-practices","title":"Best Practices","text":""},{"location":"api/agent-api/#performance-optimization","title":"Performance Optimization","text":"<pre><code># Use batch processing for multiple operations\nagent.send_message(\"Activity 1\", force_absorb_content=False)\nagent.send_message(\"Activity 2\", force_absorb_content=False)  \nagent.send_message(\"Force processing\", force_absorb_content=True)\n\n# Cache search results for repeated queries\nsearch_cache = {}\ndef cached_search(query):\n    if query not in search_cache:\n        search_cache[query] = agent.search_memory(query)\n    return search_cache[query]\n</code></pre>"},{"location":"api/agent-api/#error-handling_1","title":"Error Handling","text":"<pre><code># Robust error handling\ndef safe_agent_operation(operation, *args, **kwargs):\n    max_retries = 3\n    for attempt in range(max_retries):\n        try:\n            return operation(*args, **kwargs)\n        except Exception as e:\n            if attempt == max_retries - 1:\n                raise\n            print(f\"Attempt {attempt + 1} failed: {e}\")\n            time.sleep(2 ** attempt)  # Exponential backoff\n</code></pre>"},{"location":"api/agent-api/#whats-next","title":"What's Next?","text":"<p>Explore the Memory API for more advanced memory management:</p> <p>Memory API \u2192 </p>"},{"location":"api/memory-api/","title":"Memory API Reference","text":"<p>Advanced API reference for direct memory management and operations in MIRIX.</p> <p>Advanced API</p> <p>This API is for advanced users who need direct memory access. For most use cases, the Agent API is sufficient.</p>"},{"location":"api/memory-api/#overview","title":"Overview","text":"<p>The Memory API provides direct access to MIRIX's six memory components, allowing for advanced memory operations, custom search implementations, and fine-grained control over memory management.</p>"},{"location":"api/memory-api/#memory-manager-classes","title":"Memory Manager Classes","text":""},{"location":"api/memory-api/#core-memory-manager","title":"Core Memory Manager","text":"<pre><code>from mirix.memory import CoreMemoryManager\n\ncore_manager = CoreMemoryManager(agent_state)\n</code></pre>"},{"location":"api/memory-api/#methods","title":"Methods","text":"<pre><code># Get current core memory\ncore_memory = core_manager.get_core_memory()\n\n# Update persona block\ncore_manager.update_persona(\"I am a helpful AI assistant...\")\n\n# Update human understanding\ncore_manager.update_human(\"User prefers Python for development\")\n\n# Check memory capacity\nif core_manager.needs_rewrite():\n    core_manager.rewrite_memory()\n</code></pre>"},{"location":"api/memory-api/#episodic-memory-manager","title":"Episodic Memory Manager","text":"<pre><code>from mirix.memory import EpisodicMemoryManager\n\nepisodic_manager = EpisodicMemoryManager(agent_state)\n</code></pre>"},{"location":"api/memory-api/#methods_1","title":"Methods","text":"<pre><code># Add new episodic entry\nepisodic_manager.add_entry({\n    \"event_type\": \"user_message\",\n    \"summary\": \"User worked on documentation\",\n    \"details\": \"Created MkDocs site with Material theme...\",\n    \"actor\": \"user\",\n    \"timestamp\": \"2024-03-15T14:30:00Z\"\n})\n\n# Search episodic memories\nresults = episodic_manager.list_items(\n    query=\"documentation work\",\n    search_method=\"bm25\",\n    limit=20\n)\n\n# Get memories by time range\ntoday_memories = episodic_manager.get_memories_by_date_range(\n    start_date=\"2024-03-15T00:00:00Z\",\n    end_date=\"2024-03-15T23:59:59Z\"\n)\n</code></pre>"},{"location":"api/memory-api/#semantic-memory-manager","title":"Semantic Memory Manager","text":"<pre><code>from mirix.memory import SemanticMemoryManager\n\nsemantic_manager = SemanticMemoryManager(agent_state)\n</code></pre>"},{"location":"api/memory-api/#methods_2","title":"Methods","text":"<pre><code># Add semantic concept\nsemantic_manager.add_entry({\n    \"name\": \"MkDocs Material\",\n    \"summary\": \"Documentation framework based on MkDocs\",\n    \"details\": \"Static site generator with beautiful theming...\",\n    \"source\": \"user_interaction\"\n})\n\n# Find related concepts\nrelated = semantic_manager.find_related_concepts(\"documentation\", limit=10)\n\n# Merge duplicate concepts\nduplicates = semantic_manager.find_duplicates(similarity_threshold=0.95)\nsemantic_manager.merge_concepts(duplicates)\n</code></pre>"},{"location":"api/memory-api/#procedural-memory-manager","title":"Procedural Memory Manager","text":"<pre><code>from mirix.memory import ProceduralMemoryManager\n\nprocedural_manager = ProceduralMemoryManager(agent_state)\n</code></pre>"},{"location":"api/memory-api/#methods_3","title":"Methods","text":"<pre><code># Add workflow\nprocedural_manager.add_entry({\n    \"entry_type\": \"workflow\",\n    \"description\": \"Deploy documentation to GitHub Pages\",\n    \"steps\": [\n        \"1. Build documentation with mkdocs build\",\n        \"2. Push to main branch\",\n        \"3. GitHub Actions deploys automatically\"\n    ]\n})\n\n# Search procedures\nworkflows = procedural_manager.search_workflows(\"deployment\")\n\n# Validate workflow\nis_valid = procedural_manager.validate_workflow(workflow_id)\n</code></pre>"},{"location":"api/memory-api/#resource-memory-manager","title":"Resource Memory Manager","text":"<pre><code>from mirix.memory import ResourceMemoryManager\n\nresource_manager = ResourceMemoryManager(agent_state)\n</code></pre>"},{"location":"api/memory-api/#methods_4","title":"Methods","text":"<pre><code># Add resource\nresource_manager.add_entry({\n    \"title\": \"MIRIX Documentation Site\",\n    \"summary\": \"Complete documentation website built with MkDocs\",\n    \"resource_type\": \"website\",\n    \"content\": \"Full HTML content of the documentation...\"\n})\n\n# Get resources by type\ndocs = resource_manager.get_resources_by_type(\"markdown\")\n\n# Compress large resources\nresource_manager.compress_large_resources(threshold_mb=5)\n</code></pre>"},{"location":"api/memory-api/#knowledge-vault-manager","title":"Knowledge Vault Manager","text":"<pre><code>from mirix.memory import KnowledgeVaultManager\n\nvault_manager = KnowledgeVaultManager(agent_state)\n</code></pre>"},{"location":"api/memory-api/#methods_5","title":"Methods","text":"<pre><code># Store sensitive data\nvault_manager.add_entry({\n    \"entry_type\": \"api_key\",\n    \"source\": \"github\",\n    \"sensitivity\": \"high\",\n    \"secret_value\": \"ghp_xxxxxxxxxxxx\",\n    \"caption\": \"GitHub Personal Access Token\"\n})\n\n# Retrieve with security check\napi_key = vault_manager.get_secure_value(\n    entry_id=\"github_token_1\",\n    require_auth=True\n)\n\n# List by sensitivity\nhigh_security = vault_manager.list_by_sensitivity(\"high\")\n</code></pre>"},{"location":"api/memory-api/#search-operations","title":"Search Operations","text":""},{"location":"api/memory-api/#advanced-search","title":"Advanced Search","text":"<pre><code>from mirix.search import AdvancedSearchEngine\n\nsearch_engine = AdvancedSearchEngine(agent_state)\n\n# Multi-memory search with custom weights\nresults = search_engine.search_across_memories(\n    query=\"machine learning project\",\n    memory_weights={\n        \"episodic\": 1.0,\n        \"semantic\": 0.8,\n        \"resource\": 0.6,\n        \"procedural\": 0.4\n    },\n    search_method=\"bm25\",\n    limit=50\n)\n\n# Semantic similarity search\nsimilar = search_engine.find_semantically_similar(\n    reference_text=\"deep learning neural networks\",\n    memory_types=[\"semantic\", \"resource\"],\n    similarity_threshold=0.7\n)\n</code></pre>"},{"location":"api/memory-api/#search-filters","title":"Search Filters","text":"<pre><code># Complex search with multiple filters\nfiltered_results = search_engine.advanced_search(\n    query=\"project documentation\",\n    filters={\n        \"memory_type\": [\"resource\", \"procedural\"],\n        \"date_range\": {\n            \"start\": \"2024-01-01T00:00:00Z\",\n            \"end\": \"2024-12-31T23:59:59Z\"\n        },\n        \"sensitivity\": [\"low\", \"medium\"],\n        \"content_type\": [\"markdown\", \"text\"],\n        \"min_relevance\": 0.5\n    },\n    sort_by=\"relevance\",\n    limit=100\n)\n</code></pre>"},{"location":"api/memory-api/#memory-analytics","title":"Memory Analytics","text":""},{"location":"api/memory-api/#statistics-and-insights","title":"Statistics and Insights","text":"<pre><code>from mirix.analytics import MemoryAnalytics\n\nanalytics = MemoryAnalytics(agent_state)\n\n# Get comprehensive statistics\nstats = analytics.get_memory_statistics()\nprint(f\"Total memories: {stats['total_count']}\")\nprint(f\"Memory distribution: {stats['type_distribution']}\")\nprint(f\"Growth rate: {stats['daily_growth_rate']}\")\n\n# Analyze memory patterns\npatterns = analytics.analyze_patterns()\nprint(f\"Most active hours: {patterns['peak_hours']}\")\nprint(f\"Common topics: {patterns['frequent_topics']}\")\n\n# Memory health check\nhealth = analytics.memory_health_check()\nif health['issues']:\n    print(\"Memory issues found:\")\n    for issue in health['issues']:\n        print(f\"  - {issue}\")\n</code></pre>"},{"location":"api/memory-api/#memory-optimization","title":"Memory Optimization","text":"<pre><code>from mirix.optimization import MemoryOptimizer\n\noptimizer = MemoryOptimizer(agent_state)\n\n# Find optimization opportunities\nrecommendations = optimizer.analyze_optimization_opportunities()\n\n# Apply automatic optimizations\nresults = optimizer.optimize_memories(\n    compress_old_data=True,\n    merge_duplicates=True,\n    archive_unused=True,\n    rebuild_indexes=False\n)\n\nprint(f\"Optimization saved {results['space_saved_mb']} MB\")\n</code></pre>"},{"location":"api/memory-api/#memory-synchronization","title":"Memory Synchronization","text":""},{"location":"api/memory-api/#multi-agent-coordination","title":"Multi-Agent Coordination","text":"<pre><code>from mirix.sync import MemorySynchronizer\n\nsync = MemorySynchronizer(agent_state)\n\n# Sync with another agent\nsync_result = sync.synchronize_with_agent(other_agent_id)\n\n# Resolve conflicts\nconflicts = sync.detect_conflicts()\nfor conflict in conflicts:\n    resolution = sync.resolve_conflict(\n        conflict_id=conflict['id'],\n        strategy=\"latest_wins\"  # or \"manual\", \"merge\"\n    )\n</code></pre>"},{"location":"api/memory-api/#custom-memory-types","title":"Custom Memory Types","text":""},{"location":"api/memory-api/#extending-memory-system","title":"Extending Memory System","text":"<pre><code>from mirix.memory.base import BaseMemoryManager\n\nclass CustomMemoryManager(BaseMemoryManager):\n    def __init__(self, agent_state):\n        super().__init__(agent_state, \"custom_memory\")\n\n    def add_custom_entry(self, data):\n        # Custom logic for your memory type\n        entry = self.process_custom_data(data)\n        return self.store_entry(entry)\n\n    def search_custom(self, query, custom_params):\n        # Custom search logic\n        return self.search_with_custom_logic(query, custom_params)\n\n# Register custom memory type\ncustom_manager = CustomMemoryManager(agent_state)\n</code></pre>"},{"location":"api/memory-api/#configuration","title":"Configuration","text":""},{"location":"api/memory-api/#memory-configuration","title":"Memory Configuration","text":"<pre><code># mirix.yaml memory settings\nmemory:\n  managers:\n    core:\n      max_blocks: 10\n      rewrite_threshold: 0.9\n\n    episodic:\n      max_entries: 10000\n      archive_after_days: 90\n\n    semantic:\n      duplicate_threshold: 0.95\n      auto_merge: true\n\n    procedural:\n      validate_workflows: true\n      auto_cleanup: false\n\n    resource:\n      compression_threshold_mb: 5\n      max_content_size_mb: 100\n\n    vault:\n      encryption_enabled: true\n      audit_access: true\n\n  search:\n    default_method: \"bm25\"\n    cache_results: true\n    max_cache_size: 1000\n</code></pre>"},{"location":"api/memory-api/#error-handling","title":"Error Handling","text":""},{"location":"api/memory-api/#memory-specific-exceptions","title":"Memory-Specific Exceptions","text":"<pre><code>from mirix.exceptions import (\n    MemoryCapacityError,\n    MemoryCorruptionError,\n    MemoryAccessDeniedError,\n    MemoryNotFoundException\n)\n\ntry:\n    core_manager.add_entry(large_data)\nexcept MemoryCapacityError:\n    # Handle memory full\n    core_manager.rewrite_memory()\n\nexcept MemoryCorruptionError:\n    # Handle corrupted memory\n    core_manager.repair_memory()\n\nexcept MemoryAccessDeniedError:\n    # Handle permission issue\n    authenticate_user()\n</code></pre>"},{"location":"api/memory-api/#performance-considerations","title":"Performance Considerations","text":""},{"location":"api/memory-api/#batch-operations","title":"Batch Operations","text":"<pre><code># Efficient batch processing\nentries_to_add = [entry1, entry2, entry3, ...]\n\n# Use batch operations instead of individual adds\nsemantic_manager.add_entries_batch(entries_to_add)\n\n# Batch search across multiple queries\nqueries = [\"query1\", \"query2\", \"query3\"]\nresults = semantic_manager.search_batch(queries)\n</code></pre>"},{"location":"api/memory-api/#memory-pooling","title":"Memory Pooling","text":"<pre><code># Reuse manager instances\nfrom mirix.memory import MemoryManagerPool\n\npool = MemoryManagerPool(agent_state)\n\n# Get manager from pool\nsemantic_manager = pool.get_manager(\"semantic\")\n\n# Operations...\n\n# Return to pool when done\npool.return_manager(semantic_manager)\n</code></pre>"},{"location":"api/memory-api/#whats-next","title":"What's Next?","text":"<p>Return to explore other API features:</p> <p>Agent API \u2192 </p>"},{"location":"architecture/memory-components/","title":"Memory Components","text":"<p>MIRIX organizes information into six distinct memory components, each designed to handle specific types of data and provide optimal retrieval performance.</p>"},{"location":"architecture/memory-components/#memory-architecture-overview","title":"Memory Architecture Overview","text":"<pre><code>graph TD\n    A[Raw Input] --&gt; B[Meta Agent Analysis]\n\n    B --&gt; C[Core Memory&lt;br/&gt;Personal &amp; Persistent]\n    B --&gt; D[Episodic Memory&lt;br/&gt;Events &amp; Activities]\n    B --&gt; E[Semantic Memory&lt;br/&gt;Knowledge &amp; Concepts]\n    B --&gt; F[Procedural Memory&lt;br/&gt;Workflows &amp; Processes]\n    B --&gt; G[Resource Memory&lt;br/&gt;Documents &amp; Files]\n    B --&gt; H[Knowledge Vault&lt;br/&gt;Structured Data]\n\n    C --&gt; I[Unified Search]\n    D --&gt; I\n    E --&gt; I\n    F --&gt; I\n    G --&gt; I\n    H --&gt; I\n\n    I --&gt; J[Intelligent Responses]</code></pre>"},{"location":"architecture/memory-components/#1-core-memory","title":"1. Core Memory","text":"<p>Purpose: Persistent information that should always be visible to the agent when interacting with the user.</p> <p>Inspired by: MemGPT's core memory architecture</p>"},{"location":"architecture/memory-components/#structure","title":"Structure","text":"<p>Core Memory is organized in multiple blocks with line indicators:</p> <pre><code>Line 1: User's name is David\nLine 2: User prefers coffee over tea\nLine 3: User works as a software engineer\nLine 4: User enjoys reading sci-fi novels\n...\n</code></pre>"},{"location":"architecture/memory-components/#key-features","title":"Key Features","text":"<ul> <li>Persistent Visibility: Always available during conversations</li> <li>Two Main Blocks:</li> <li><code>persona</code>: The agent's personality and behavior</li> <li><code>human</code>: Saved understanding of the user</li> <li>Auto-Rewriting: When blocks exceed 90% capacity, they are automatically rewritten to maintain optimal size</li> <li>Essential Information: Stores critical facts that define the user-agent relationship</li> </ul>"},{"location":"architecture/memory-components/#example-content","title":"Example Content","text":"<pre><code>=== PERSONA ===\nLine 1: I am MIRIX, a helpful AI assistant specializing in memory management\nLine 2: I track user activities and provide context-aware assistance\nLine 3: I maintain detailed memories of user interactions and preferences\n\n=== HUMAN ===\nLine 1: User's name is Sarah, works as a data scientist\nLine 2: User prefers PostgreSQL over SQLite for databases\nLine 3: User is currently working on a machine learning project\nLine 4: User has meetings every Tuesday at 2 PM\n</code></pre>"},{"location":"architecture/memory-components/#2-episodic-memory","title":"2. Episodic Memory","text":"<p>Purpose: Captures context-specific events and temporal activities, serving as a summarization or calendar of user behaviors.</p>"},{"location":"architecture/memory-components/#structure_1","title":"Structure","text":"<p>Each episodic entry contains:</p> <pre><code>{\n  \"event_type\": \"user_message\",\n  \"summary\": \"User reviewed quarterly sales report\",\n  \"details\": \"Detailed analysis of Q3 sales performance, identified key growth areas in mobile segment, discussed strategies with marketing team\",\n  \"actor\": \"user\",\n  \"timestamp\": \"2025-03-05 10:15\"\n}\n</code></pre>"},{"location":"architecture/memory-components/#event-types","title":"Event Types","text":"<ul> <li><code>user_message</code>: Direct user communications</li> <li><code>inferred_results</code>: System-inferred activities from screen capture</li> <li><code>system_notification</code>: Automated system events</li> <li><code>workflow_completion</code>: Completed task sequences</li> </ul>"},{"location":"architecture/memory-components/#example-entries","title":"Example Entries","text":"<pre><code>[\n  {\n    \"event_type\": \"user_message\",\n    \"summary\": \"Started working on documentation\",\n    \"details\": \"Opened VSCode, created new markdown files for project documentation, began writing API specifications\",\n    \"actor\": \"user\",\n    \"timestamp\": \"2025-03-05 09:30\"\n  },\n  {\n    \"event_type\": \"inferred_results\",\n    \"summary\": \"Switched to email client\",\n    \"details\": \"Closed development environment, opened Gmail, reviewed 5 new emails, responded to client inquiry about project timeline\",\n    \"actor\": \"assistant\",\n    \"timestamp\": \"2025-03-05 10:45\"\n  }\n]\n</code></pre>"},{"location":"architecture/memory-components/#3-semantic-memory","title":"3. Semantic Memory","text":"<p>Purpose: Maintains general knowledge, concepts, and abstracted information independent of temporal context.</p>"},{"location":"architecture/memory-components/#structure_2","title":"Structure","text":"<p>Each semantic entry includes:</p> <pre><code>{\n  \"name\": \"PostgreSQL\",\n  \"summary\": \"Open-source relational database management system\",\n  \"details\": \"Powerful, enterprise-grade database with advanced features like JSONB support, full-text search, and vector extensions. Preferred by user for its performance and reliability.\",\n  \"source\": \"user_interaction\"\n}\n</code></pre>"},{"location":"architecture/memory-components/#content-types","title":"Content Types","text":"<ul> <li>Factual Knowledge: \"Harry Potter is written by J.K. Rowling\"</li> <li>Relationships: \"John is a good friend who likes jogging\"</li> <li>Concepts: \"Machine learning algorithms and their applications\"</li> <li>Preferences: \"User prefers dark mode in development environments\"</li> </ul>"},{"location":"architecture/memory-components/#example-entries_1","title":"Example Entries","text":"<pre><code>[\n  {\n    \"name\": \"MkDocs Material\",\n    \"summary\": \"Documentation framework based on MkDocs\",\n    \"details\": \"Static site generator that creates beautiful documentation sites from Markdown files. Features include responsive design, search functionality, and extensive customization options.\",\n    \"source\": \"documentation_project\"\n  },\n  {\n    \"name\": \"Team Standup Meeting\",\n    \"summary\": \"Daily team synchronization meeting\",\n    \"details\": \"Occurs every weekday at 9 AM, attended by development team to discuss progress, blockers, and daily goals. Usually lasts 15-20 minutes.\",\n    \"source\": \"recurring_activity\"\n  }\n]\n</code></pre>"},{"location":"architecture/memory-components/#4-procedural-memory","title":"4. Procedural Memory","text":"<p>Purpose: Records process workflows and step-by-step instructions for accomplishing specific tasks.</p>"},{"location":"architecture/memory-components/#structure_3","title":"Structure","text":"<p>Each procedural entry contains:</p> <pre><code>{\n  \"entry_type\": \"workflow\",\n  \"description\": \"Deploy application to production\",\n  \"steps\": [\n    \"1. Run test suite to ensure all tests pass\",\n    \"2. Create production build with 'npm run build'\",\n    \"3. Review build artifacts for any issues\",\n    \"4. Deploy to staging environment first\",\n    \"5. Perform smoke tests on staging\",\n    \"6. Deploy to production using CI/CD pipeline\",\n    \"7. Monitor application metrics post-deployment\"\n  ]\n}\n</code></pre>"},{"location":"architecture/memory-components/#entry-types","title":"Entry Types","text":"<ul> <li><code>workflow</code>: Multi-step processes</li> <li><code>guide</code>: How-to instructions</li> <li><code>script</code>: Automated procedures</li> </ul>"},{"location":"architecture/memory-components/#example-entries_2","title":"Example Entries","text":"<pre><code>[\n  {\n    \"entry_type\": \"workflow\",\n    \"description\": \"Setting up new development environment\",\n    \"steps\": [\n      \"1. Install Python 3.11 or later\",\n      \"2. Set up virtual environment with 'python -m venv venv'\",\n      \"3. Activate virtual environment\",\n      \"4. Install dependencies with 'pip install -r requirements.txt'\",\n      \"5. Configure environment variables in .env file\",\n      \"6. Initialize database with 'python manage.py migrate'\",\n      \"7. Run development server with 'python manage.py runserver'\"\n    ]\n  },\n  {\n    \"entry_type\": \"guide\",\n    \"description\": \"Troubleshooting PostgreSQL connection issues\",\n    \"steps\": [\n      \"1. Check if PostgreSQL service is running\",\n      \"2. Verify database exists with 'psql -l'\",\n      \"3. Test connection with 'psql -U username -d database'\",\n      \"4. Check firewall settings if connecting remotely\",\n      \"5. Verify authentication configuration in pg_hba.conf\"\n    ]\n  }\n]\n</code></pre>"},{"location":"architecture/memory-components/#5-resource-memory","title":"5. Resource Memory","text":"<p>Purpose: Manages active documents and project-related files that the user interacts with.</p>"},{"location":"architecture/memory-components/#structure_4","title":"Structure","text":"<p>Each resource entry includes:</p> <pre><code>{\n  \"title\": \"Project Proposal - Q4 2024\",\n  \"summary\": \"Comprehensive proposal for new mobile application development project including timeline, budget, and technical specifications\",\n  \"resource_type\": \"pdf_text\",\n  \"content\": \"# Project Proposal\\n\\n## Executive Summary\\nThis proposal outlines the development of a new mobile application...\\n\\n## Technical Requirements\\n- React Native framework\\n- PostgreSQL database\\n- AWS cloud infrastructure...\"\n}\n</code></pre>"},{"location":"architecture/memory-components/#resource-types","title":"Resource Types","text":"<ul> <li><code>doc</code>: Microsoft Word documents</li> <li><code>markdown</code>: Markdown files</li> <li><code>pdf_text</code>: Extracted text from PDFs</li> <li><code>image</code>: Image files with descriptions</li> <li><code>voice_transcript</code>: Transcribed audio content</li> <li><code>code</code>: Source code files</li> <li><code>spreadsheet</code>: Excel/CSV data</li> </ul>"},{"location":"architecture/memory-components/#example-entries_3","title":"Example Entries","text":"<pre><code>[\n  {\n    \"title\": \"API Documentation Draft\",\n    \"summary\": \"Initial draft of REST API documentation for the customer management system, includes endpoint specifications and example requests\",\n    \"resource_type\": \"markdown\",\n    \"content\": \"# Customer Management API\\n\\n## Overview\\nThis API provides endpoints for managing customer data...\\n\\n## Endpoints\\n\\n### GET /api/customers\\nRetrieve list of customers...\"\n  },\n  {\n    \"title\": \"Meeting Recording - Sprint Planning\",\n    \"summary\": \"Voice recording from sprint planning meeting discussing user stories and development priorities for next iteration\",\n    \"resource_type\": \"voice_transcript\",\n    \"content\": \"Transcript: 'Let's start with the user authentication story. Based on our previous discussion, we need to implement OAuth 2.0 integration...'\"\n  }\n]\n</code></pre>"},{"location":"architecture/memory-components/#6-knowledge-vault","title":"6. Knowledge Vault","text":"<p>Purpose: Securely stores structured personal data such as addresses, phone numbers, contacts, and credentials.</p>"},{"location":"architecture/memory-components/#structure_5","title":"Structure","text":"<p>Each vault entry contains:</p> <pre><code>{\n  \"entry_type\": \"credential\",\n  \"source\": \"github\",\n  \"sensitivity\": \"high\",\n  \"secret_value\": \"ghp_xxxxxxxxxxxxxxxxxxxx\",\n  \"caption\": \"GitHub Personal Access Token for API access\"\n}\n</code></pre>"},{"location":"architecture/memory-components/#entry-types_1","title":"Entry Types","text":"<ul> <li><code>credential</code>: Login information and tokens</li> <li><code>bookmark</code>: Important URLs and links</li> <li><code>api_key</code>: Service API keys and secrets</li> <li><code>contact_info</code>: Personal contact information</li> </ul>"},{"location":"architecture/memory-components/#sensitivity-levels","title":"Sensitivity Levels","text":"<ul> <li><code>low</code>: General bookmarks and public information</li> <li><code>medium</code>: Contact information and non-critical data</li> <li><code>high</code>: Passwords, API keys, and sensitive credentials</li> </ul>"},{"location":"architecture/memory-components/#security-features","title":"Security Features","text":"<ul> <li>Encryption: Sensitive data encrypted at rest</li> <li>Access Control: Restricted access based on sensitivity level</li> <li>Audit Trail: All access to sensitive data is logged</li> <li>Automatic Expiration: Credentials can have expiration dates</li> </ul>"},{"location":"architecture/memory-components/#example-entries_4","title":"Example Entries","text":"<pre><code>[\n  {\n    \"entry_type\": \"api_key\",\n    \"source\": \"openai\",\n    \"sensitivity\": \"high\",\n    \"secret_value\": \"sk-proj-xxxxxxxxxxxxxxxxxxxx\",\n    \"caption\": \"OpenAI API key for ChatGPT integration\"\n  },\n  {\n    \"entry_type\": \"bookmark\",\n    \"source\": \"user_provided\",\n    \"sensitivity\": \"low\",\n    \"secret_value\": \"https://docs.mirix.ai/\",\n    \"caption\": \"MIRIX documentation website\"\n  },\n  {\n    \"entry_type\": \"contact_info\",\n    \"source\": \"user_profile\",\n    \"sensitivity\": \"medium\",\n    \"secret_value\": \"john.doe@example.com\",\n    \"caption\": \"Primary email address\"\n  }\n]\n</code></pre>"},{"location":"architecture/memory-components/#memory-interaction-patterns","title":"Memory Interaction Patterns","text":""},{"location":"architecture/memory-components/#cross-memory-relationships","title":"Cross-Memory Relationships","text":"<pre><code>graph LR\n    A[Core Memory] --&gt; B[Episodic Memory]\n    A --&gt; C[Semantic Memory]\n\n    B --&gt; D[Procedural Memory]\n    C --&gt; D\n\n    E[Resource Memory] --&gt; C\n    E --&gt; D\n\n    F[Knowledge Vault] --&gt; A\n    F --&gt; E</code></pre>"},{"location":"architecture/memory-components/#search-integration","title":"Search Integration","text":"<p>All memory components support unified search:</p> <pre><code># Search across all memory types\nresults = search_memory(\n    query=\"machine learning project\",\n    memory_types=[\"core\", \"episodic\", \"semantic\", \"procedural\", \"resource\"],\n    limit=20\n)\n</code></pre>"},{"location":"architecture/memory-components/#memory-optimization","title":"Memory Optimization","text":""},{"location":"architecture/memory-components/#automatic-cleanup","title":"Automatic Cleanup","text":"<ul> <li>Core Memory: Rewrites blocks when approaching capacity</li> <li>Episodic Memory: Archives old entries based on relevance</li> <li>Semantic Memory: Merges duplicate concepts</li> <li>Procedural Memory: Updates workflows based on usage patterns</li> <li>Resource Memory: Compresses or removes unused resources</li> <li>Knowledge Vault: Expires outdated credentials</li> </ul>"},{"location":"architecture/memory-components/#performance-tuning","title":"Performance Tuning","text":"<ul> <li>Indexing: Optimized database indexes for fast retrieval</li> <li>Caching: Frequently accessed data cached in memory</li> <li>Compression: Large content compressed to save space</li> <li>Partitioning: Data partitioned by date and type for efficient queries</li> </ul>"},{"location":"architecture/memory-components/#best-practices","title":"Best Practices","text":""},{"location":"architecture/memory-components/#memory-organization","title":"Memory Organization","text":"<ol> <li>Keep Core Memory Concise: Only essential, persistent information</li> <li>Detailed Episodic Entries: Rich context for better retrieval</li> <li>Abstract Semantic Concepts: Focus on reusable knowledge</li> <li>Actionable Procedures: Clear, step-by-step instructions</li> <li>Comprehensive Resources: Full content for better context</li> <li>Secure Vault Management: Proper sensitivity classification</li> </ol>"},{"location":"architecture/memory-components/#search-optimization","title":"Search Optimization","text":"<ul> <li>Use specific queries for better results</li> <li>Combine memory types for comprehensive answers</li> <li>Leverage field-specific search when needed</li> <li>Regular memory cleanup for optimal performance</li> </ul>"},{"location":"architecture/memory-components/#whats-next","title":"What's Next?","text":"<p>Learn about MIRIX's advanced search capabilities:</p> <p>Search Capabilities \u2192 </p>"},{"location":"architecture/multi-agent-system/","title":"Multi-Agent System","text":"<p>MIRIX consists of eight specialized agents that work collaboratively to process your digital activities and manage memory efficiently.</p>"},{"location":"architecture/multi-agent-system/#agent-overview","title":"Agent Overview","text":"<pre><code>graph TB\n    subgraph \"Input Processing\"\n        A[User Input] --&gt; B[Meta Agent]\n    end\n\n    subgraph \"Memory Management Agents\"\n        C[Core Memory Manager]\n        D[Episodic Memory Manager]\n        E[Semantic Memory Manager]\n        F[Procedural Memory Manager]\n        G[Resource Memory Manager]\n        H[Knowledge Vault Manager]\n    end\n\n    subgraph \"User Interaction\"\n        I[Chat Agent]\n    end\n\n    subgraph \"Memory Base\"\n        J[(Shared Memory Database)]\n    end\n\n    B --&gt; C\n    B --&gt; D\n    B --&gt; E\n    B --&gt; F\n    B --&gt; G\n    B --&gt; H\n\n    C --&gt; J\n    D --&gt; J\n    E --&gt; J\n    F --&gt; J\n    G --&gt; J\n    H --&gt; J\n\n    I --&gt; J\n    J --&gt; I</code></pre>"},{"location":"architecture/multi-agent-system/#agent-roles","title":"Agent Roles","text":""},{"location":"architecture/multi-agent-system/#meta-agent","title":"Meta Agent","text":"<p>Role: Central coordinator and content analyzer</p> <p>Responsibilities: - Analyzes incoming user content (text, images, voice) - Determines which memory components need updates - Routes specific instructions to relevant Memory Managers - Orchestrates the overall information processing workflow</p> <p>Workflow: <pre><code># Pseudo-code for Meta Agent processing\ndef process_user_input(content):\n    analysis = analyze_content(content)\n\n    if contains_personal_info(analysis):\n        route_to_core_memory_manager(analysis)\n\n    if contains_activities(analysis):\n        route_to_episodic_memory_manager(analysis)\n\n    if contains_knowledge(analysis):\n        route_to_semantic_memory_manager(analysis)\n\n    # ... and so on\n</code></pre></p>"},{"location":"architecture/multi-agent-system/#chat-agent","title":"Chat Agent","text":"<p>Role: Natural language conversation interface</p> <p>Responsibilities: - Handles user queries and conversations - Searches across all memory components using <code>search_memory()</code> - Synthesizes retrieved information into contextual responses - Maintains conversation flow and context</p> <p>Search Process: <pre><code>def respond_to_query(user_query):\n    # Search across all memory types\n    search_results = search_memory(\n        query=user_query,\n        search_across=['core', 'episodic', 'semantic', \n                      'procedural', 'resource', 'vault']\n    )\n\n    # Generate contextual response\n    return synthesize_response(search_results, user_query)\n</code></pre></p>"},{"location":"architecture/multi-agent-system/#memory-management-agents","title":"Memory Management Agents","text":"<p>Each memory component has a dedicated agent that specializes in managing that specific type of information.</p>"},{"location":"architecture/multi-agent-system/#core-memory-manager","title":"Core Memory Manager","text":"<p>Manages: Personal preferences, user identity, essential facts</p> <p>Processing Logic: - Identifies user preferences and personality traits - Updates persona and human understanding blocks - Maintains consistency across conversations - Handles memory rewriting when blocks exceed 90% capacity</p>"},{"location":"architecture/multi-agent-system/#episodic-memory-manager","title":"Episodic Memory Manager","text":"<p>Manages: Time-based activities and events</p> <p>Processing Logic: - Captures temporal context and user activities - Creates event summaries with timestamps - Tracks what the user has done and is currently doing - Links activities to specific time periods</p>"},{"location":"architecture/multi-agent-system/#semantic-memory-manager","title":"Semantic Memory Manager","text":"<p>Manages: General knowledge and concepts</p> <p>Processing Logic: - Extracts factual information independent of time - Stores concepts, definitions, and relationships - Maintains knowledge about people, places, and things - Links related concepts for better retrieval</p>"},{"location":"architecture/multi-agent-system/#procedural-memory-manager","title":"Procedural Memory Manager","text":"<p>Manages: Workflows and step-by-step processes</p> <p>Processing Logic: - Identifies process patterns and workflows - Stores step-by-step instructions - Recognizes recurring task patterns - Optimizes workflow documentation</p>"},{"location":"architecture/multi-agent-system/#resource-memory-manager","title":"Resource Memory Manager","text":"<p>Manages: Documents, files, and content</p> <p>Processing Logic: - Processes document content and context - Maintains file relationships and project context - Stores full or partial content as needed - Tracks document usage patterns</p>"},{"location":"architecture/multi-agent-system/#knowledge-vault-manager","title":"Knowledge Vault Manager","text":"<p>Manages: Structured data and credentials</p> <p>Processing Logic: - Identifies sensitive information (passwords, API keys) - Categorizes data by sensitivity level - Maintains secure storage practices - Prevents accidental exposure of sensitive data</p>"},{"location":"architecture/multi-agent-system/#workflow-coordination","title":"Workflow Coordination","text":""},{"location":"architecture/multi-agent-system/#1-input-processing-pipeline","title":"1. Input Processing Pipeline","text":"<pre><code>sequenceDiagram\n    participant U as User Input\n    participant M as Meta Agent\n    participant MM as Memory Managers\n    participant DB as Memory Base\n\n    U-&gt;&gt;M: Send content\n    M-&gt;&gt;M: Analyze content type\n    M-&gt;&gt;MM: Route to relevant managers\n    MM-&gt;&gt;MM: Process information\n    MM-&gt;&gt;DB: Update memory components\n    DB--&gt;&gt;MM: Confirm updates\n    MM--&gt;&gt;M: Processing complete\n    M--&gt;&gt;U: Acknowledgment</code></pre>"},{"location":"architecture/multi-agent-system/#2-memory-consolidation-process","title":"2. Memory Consolidation Process","text":"<p>Batch Processing: - Agents accumulate information until reaching threshold - Trigger batch processing for efficiency - Single function call per agent for comprehensive updates</p> <p>Smart Routing: - Meta Agent uses sophisticated logic to determine distribution - Agents can skip updates if no relevant information detected - Prevents unnecessary processing and maintains efficiency</p>"},{"location":"architecture/multi-agent-system/#3-conversational-retrieval-system","title":"3. Conversational Retrieval System","text":"<pre><code>sequenceDiagram\n    participant U as User Query\n    participant C as Chat Agent\n    participant S as search_memory()\n    participant DB as Memory Base\n    participant R as Response\n\n    U-&gt;&gt;C: Ask question\n    C-&gt;&gt;S: Call search function\n    S-&gt;&gt;DB: Query all memory types\n    DB--&gt;&gt;S: Return relevant results\n    S--&gt;&gt;C: Consolidated results\n    C-&gt;&gt;C: Synthesize response\n    C-&gt;&gt;R: Generate answer\n    R--&gt;&gt;U: Intelligent response</code></pre>"},{"location":"architecture/multi-agent-system/#performance-optimizations","title":"Performance Optimizations","text":""},{"location":"architecture/multi-agent-system/#intelligent-routing-logic","title":"Intelligent Routing Logic","text":"<p>The Meta Agent uses sophisticated analysis to route information efficiently:</p> <pre><code>def route_information(content_analysis):\n    routing_decisions = []\n\n    # User preferences and personality traits\n    if has_personal_preferences(content_analysis):\n        routing_decisions.append(('core_memory', extract_preferences(content_analysis)))\n\n    # Activities and temporal events\n    if has_temporal_activities(content_analysis):\n        routing_decisions.append(('episodic_memory', extract_activities(content_analysis)))\n\n    # General knowledge and concepts\n    if has_knowledge_facts(content_analysis):\n        routing_decisions.append(('semantic_memory', extract_knowledge(content_analysis)))\n\n    # Step-by-step processes and guides\n    if has_procedural_info(content_analysis):\n        routing_decisions.append(('procedural_memory', extract_procedures(content_analysis)))\n\n    # Documents and file contents\n    if has_document_content(content_analysis):\n        routing_decisions.append(('resource_memory', extract_resources(content_analysis)))\n\n    # Structured data and credentials\n    if has_structured_data(content_analysis):\n        routing_decisions.append(('knowledge_vault', extract_structured_data(content_analysis)))\n\n    return routing_decisions\n</code></pre>"},{"location":"architecture/multi-agent-system/#concurrent-processing","title":"Concurrent Processing","text":"<ul> <li>Memory Managers work independently but share the same memory base</li> <li>Parallel processing of different memory types</li> <li>Efficient resource utilization through smart scheduling</li> </ul>"},{"location":"architecture/multi-agent-system/#single-function-call-architecture","title":"Single Function Call Architecture","text":"<ul> <li>Each agent makes comprehensive updates in a single function call</li> <li>Reduces database round trips and improves performance</li> <li>Maintains consistency across memory components</li> </ul>"},{"location":"architecture/multi-agent-system/#error-handling-and-resilience","title":"Error Handling and Resilience","text":""},{"location":"architecture/multi-agent-system/#graceful-degradation","title":"Graceful Degradation","text":"<ul> <li>Agents can skip updates if processing fails</li> <li>System continues operating even if individual agents encounter errors</li> <li>Automatic retry mechanisms for transient failures</li> </ul>"},{"location":"architecture/multi-agent-system/#data-consistency","title":"Data Consistency","text":"<ul> <li>Shared memory base ensures consistency across agents</li> <li>Transaction-based updates prevent data corruption</li> <li>Automatic rollback on processing failures</li> </ul>"},{"location":"architecture/multi-agent-system/#configuration-and-customization","title":"Configuration and Customization","text":""},{"location":"architecture/multi-agent-system/#agent-behavior-tuning","title":"Agent Behavior Tuning","text":"<pre><code># mirix.yaml configuration\nagents:\n  meta_agent:\n    analysis_depth: \"detailed\"\n    routing_threshold: 0.7\n\n  memory_managers:\n    batch_size: 20\n    processing_interval: 300  # seconds\n\n  chat_agent:\n    search_method: \"bm25\"\n    max_results: 50\n</code></pre>"},{"location":"architecture/multi-agent-system/#memory-type-priorities","title":"Memory Type Priorities","text":"<p>Configure which memory types should be prioritized for different content types:</p> <pre><code>routing_priorities:\n  personal_info: [\"core_memory\", \"knowledge_vault\"]\n  activities: [\"episodic_memory\", \"procedural_memory\"]\n  documents: [\"resource_memory\", \"semantic_memory\"]\n  knowledge: [\"semantic_memory\", \"procedural_memory\"]\n</code></pre> <p>This multi-agent architecture ensures that MIRIX can efficiently process and organize your digital activities while maintaining high performance and accuracy.</p>"},{"location":"architecture/multi-agent-system/#whats-next","title":"What's Next?","text":"<p>Dive deeper into the memory components that power this system:</p> <p>Memory Components \u2192 </p>"},{"location":"architecture/search-capabilities/","title":"Search Capabilities","text":"<p>MIRIX provides multiple sophisticated search methods for retrieving information from its memory components, with PostgreSQL-native full-text search as the primary implementation for optimal performance and scalability.</p>"},{"location":"architecture/search-capabilities/#search-methods-overview","title":"Search Methods Overview","text":"<p>MIRIX supports four distinct search methods, each optimized for different use cases:</p> Method Description Best For Performance <code>bm25</code> RECOMMENDED - PostgreSQL native full-text search Most queries, production use Excellent <code>embedding</code> Vector similarity search using embeddings Semantic similarity, conceptual queries Good <code>string_match</code> Simple string containment search Exact text matching Fast <code>fuzzy_match</code> Fuzzy string matching (legacy) Typo tolerance Moderate"},{"location":"architecture/search-capabilities/#postgresql-native-bm25-implementation","title":"PostgreSQL Native BM25 Implementation","text":""},{"location":"architecture/search-capabilities/#architecture","title":"Architecture","text":"<p>All memory managers (Episodic, Semantic, Procedural, Resource, Knowledge Vault) use PostgreSQL's native <code>ts_rank_cd</code> function for BM25-like scoring directly in the database.</p> <pre><code>graph TB\n    A[Search Query] --&gt; B[Query Preprocessing]\n    B --&gt; C[PostgreSQL ts_query]\n    C --&gt; D[GIN Index Lookup]\n    D --&gt; E[ts_rank_cd Scoring]\n    E --&gt; F[Field Weighting]\n    F --&gt; G[Document Length Normalization]\n    G --&gt; H[Ranked Results]</code></pre>"},{"location":"architecture/search-capabilities/#key-technical-features","title":"Key Technical Features","text":""},{"location":"architecture/search-capabilities/#gin-index-utilization","title":"GIN Index Utilization","text":"<ul> <li>Leverages existing GIN indexes on tsvector expressions</li> <li>Lightning-fast searches even on large datasets</li> <li>Automatic index maintenance by PostgreSQL</li> </ul>"},{"location":"architecture/search-capabilities/#advanced-query-logic","title":"Advanced Query Logic","text":"<pre><code>-- Smart AND \u2192 OR fallback for optimal precision and recall\nSELECT *, ts_rank_cd(search_vector, query, 32) as rank\nFROM memory_table \nWHERE search_vector @@ plainto_tsquery('machine &amp; learning')\nORDER BY rank DESC\nLIMIT 50;\n\n-- If no results, fallback to OR query\nSELECT *, ts_rank_cd(search_vector, query, 32) as rank  \nFROM memory_table\nWHERE search_vector @@ plainto_tsquery('machine | learning')\nORDER BY rank DESC\nLIMIT 50;\n</code></pre>"},{"location":"architecture/search-capabilities/#field-weighting-system","title":"Field Weighting System","text":"<p>PostgreSQL's A, B, C, D priority weighting system: - A: Highest priority (titles, names) - B: High priority (summaries, descriptions) - C: Medium priority (detailed content) - D: Low priority (metadata, tags)</p>"},{"location":"architecture/search-capabilities/#document-length-normalization","title":"Document Length Normalization","text":"<p>Uses <code>ts_rank_cd</code> with normalization parameter 32 for optimal scoring: <pre><code>ts_rank_cd(search_vector, query, 32)\n-- 32 = normalize by document length + logarithmic normalization\n</code></pre></p>"},{"location":"architecture/search-capabilities/#performance-optimizations","title":"Performance Optimizations","text":""},{"location":"architecture/search-capabilities/#memory-efficiency","title":"Memory Efficiency","text":"<ul> <li>Zero In-Memory Loading: Eliminates the need to load all documents into Python memory</li> <li>Database-Level Processing: All ranking and filtering done at the PostgreSQL level</li> <li>Scalable Architecture: Performance scales with your PostgreSQL setup</li> </ul>"},{"location":"architecture/search-capabilities/#query-optimization","title":"Query Optimization","text":""},{"location":"architecture/search-capabilities/#smart-query-strategy","title":"Smart Query Strategy","text":"<pre><code>def search_with_fallback(query, limit=50):\n    # 1. Try precise AND query first\n    and_results = execute_sql(f\"\"\"\n        SELECT * FROM memory_table \n        WHERE search_vector @@ plainto_tsquery('{\" &amp; \".join(query.split())}')\n        ORDER BY ts_rank_cd(search_vector, query, 32) DESC\n        LIMIT {limit}\n    \"\"\")\n\n    if len(and_results) &gt;= limit * 0.3:  # Good results\n        return and_results\n\n    # 2. Fall back to broader OR query\n    or_results = execute_sql(f\"\"\"\n        SELECT * FROM memory_table\n        WHERE search_vector @@ plainto_tsquery('{\" | \".join(query.split())}') \n        ORDER BY ts_rank_cd(search_vector, query, 32) DESC\n        LIMIT {limit}\n    \"\"\")\n\n    return or_results\n</code></pre>"},{"location":"architecture/search-capabilities/#prefix-matching","title":"Prefix Matching","text":"<p>Supports partial word matching with <code>:*</code> operators: <pre><code>SELECT * FROM memory_table\nWHERE search_vector @@ to_tsquery('machin:* &amp; learn:*')\nORDER BY ts_rank_cd(search_vector, query, 32) DESC;\n</code></pre></p>"},{"location":"architecture/search-capabilities/#field-specific-search","title":"Field-Specific Search","text":"<p>Can target specific fields or search across all fields with weighting: <pre><code># Search specific field\nresults = memory_manager.list_items(\n    query=\"neural networks\",\n    search_field=\"summary\",\n    search_method=\"bm25\"\n)\n\n# Search all fields with weighting\nresults = memory_manager.list_items(\n    query=\"neural networks\", \n    search_method=\"bm25\"  # Uses pre-configured field weights\n)\n</code></pre></p>"},{"location":"architecture/search-capabilities/#search-field-specifications","title":"Search Field Specifications","text":"<p>Each memory type supports field-specific searches:</p>"},{"location":"architecture/search-capabilities/#episodic-memory","title":"Episodic Memory","text":"<ul> <li><code>summary</code>: Brief event description</li> <li><code>details</code>: Comprehensive event information  </li> <li><code>actor</code>: Who performed the action (user/assistant)</li> <li><code>event_type</code>: Category of event</li> </ul>"},{"location":"architecture/search-capabilities/#semantic-memory","title":"Semantic Memory","text":"<ul> <li><code>name</code>: Concept or object name</li> <li><code>summary</code>: Concise explanation</li> <li><code>details</code>: Extended description</li> <li><code>source</code>: Knowledge origin</li> </ul>"},{"location":"architecture/search-capabilities/#procedural-memory","title":"Procedural Memory","text":"<ul> <li><code>summary</code>: Process description</li> <li><code>steps</code>: Detailed instructions</li> <li><code>entry_type</code>: Type of procedure (workflow/guide/script)</li> </ul>"},{"location":"architecture/search-capabilities/#resource-memory","title":"Resource Memory","text":"<ul> <li><code>title</code>: Resource name</li> <li><code>summary</code>: Brief description with context</li> <li><code>content</code>: Full document content</li> <li><code>resource_type</code>: File format type</li> </ul>"},{"location":"architecture/search-capabilities/#knowledge-vault","title":"Knowledge Vault","text":"<ul> <li><code>caption</code>: Description of stored item</li> <li><code>source</code>: Data origin</li> <li><code>entry_type</code>: Type of data (credential/bookmark/contact)</li> <li><code>secret_value</code>: Actual stored value</li> <li><code>sensitivity</code>: Security classification</li> </ul>"},{"location":"architecture/search-capabilities/#usage-examples","title":"Usage Examples","text":""},{"location":"architecture/search-capabilities/#basic-search","title":"Basic Search","text":"<pre><code>from mirix.agent import AgentWrapper\n\nagent = AgentWrapper(\"./configs/mirix.yaml\")\n\n# Basic search across all memory types\nresults = agent.search_memory(\"machine learning algorithms\")\n</code></pre>"},{"location":"architecture/search-capabilities/#advanced-search-options","title":"Advanced Search Options","text":"<pre><code># PostgreSQL BM25 search (recommended)\nresults = memory_manager.list_items(\n    agent_state=agent_state,\n    query=\"machine learning algorithms\",\n    search_method=\"bm25\",\n    limit=50\n)\n\n# Field-specific search\nresults = memory_manager.list_items(\n    agent_state=agent_state,\n    query=\"neural networks\",\n    search_field=\"summary\",\n    search_method=\"bm25\", \n    limit=20\n)\n\n# Vector similarity search\nresults = memory_manager.list_items(\n    agent_state=agent_state,\n    query=\"deep learning concepts\",\n    search_method=\"embedding\",\n    limit=30\n)\n</code></pre>"},{"location":"architecture/search-capabilities/#multi-memory-search","title":"Multi-Memory Search","text":"<pre><code># Search across specific memory types\nresults = agent.search_memory(\n    query=\"project documentation\",\n    memory_types=[\"resource\", \"procedural\", \"semantic\"],\n    limit=25\n)\n\n# Search with time constraints (episodic memory)\nresults = agent.search_memory(\n    query=\"yesterday's meetings\",\n    memory_types=[\"episodic\"],\n    time_range=\"last_24_hours\"\n)\n</code></pre>"},{"location":"architecture/search-capabilities/#performance-benchmarks","title":"Performance Benchmarks","text":""},{"location":"architecture/search-capabilities/#postgresql-vs-in-memory-processing","title":"PostgreSQL vs In-Memory Processing","text":"Dataset Size PostgreSQL BM25 In-Memory BM25 Speedup 1,000 entries 2ms 120ms 60x 10,000 entries 5ms 1,200ms 240x 100,000 entries 15ms 12,000ms 800x"},{"location":"architecture/search-capabilities/#memory-usage-comparison","title":"Memory Usage Comparison","text":"Method Memory Usage Scalability PostgreSQL BM25 ~50MB baseline Linear In-Memory BM25 ~500MB per 10k docs Exponential Vector Search ~200MB per 10k docs Linear"},{"location":"architecture/search-capabilities/#response-time-analysis","title":"Response Time Analysis","text":"<pre><code>xychart-beta\n    title \"Search Response Time by Method\"\n    x-axis [\"1K docs\", \"10K docs\", \"100K docs\", \"1M docs\"]\n    y-axis \"Response Time (ms)\" 0 --&gt; 1000\n    bar [2, 5, 15, 45]\n    bar [120, 1200, 12000, 120000]</code></pre>"},{"location":"architecture/search-capabilities/#search-quality-optimization","title":"Search Quality Optimization","text":""},{"location":"architecture/search-capabilities/#query-preprocessing","title":"Query Preprocessing","text":"<pre><code>def preprocess_query(query):\n    # Remove stop words\n    query = remove_stopwords(query)\n\n    # Handle special characters\n    query = escape_special_chars(query)\n\n    # Expand abbreviations\n    query = expand_abbreviations(query)\n\n    # Add context from recent queries\n    query = add_search_context(query)\n\n    return query\n</code></pre>"},{"location":"architecture/search-capabilities/#relevance-scoring","title":"Relevance Scoring","text":"<p>The BM25 algorithm considers: - Term Frequency: How often terms appear in documents - Inverse Document Frequency: Rarity of terms across corpus - Document Length: Normalization for document size - Field Weights: Importance of different fields</p>"},{"location":"architecture/search-capabilities/#result-ranking-factors","title":"Result Ranking Factors","text":"<ol> <li>Exact Match Bonus: Perfect phrase matches get higher scores</li> <li>Recency Boost: Recent activities weighted higher in episodic memory</li> <li>User Preference: Frequently accessed content ranked higher</li> <li>Context Relevance: Results matching current conversation context</li> </ol>"},{"location":"architecture/search-capabilities/#advanced-features","title":"Advanced Features","text":""},{"location":"architecture/search-capabilities/#autocomplete-and-suggestions","title":"Autocomplete and Suggestions","text":"<pre><code># Get search suggestions\nsuggestions = agent.get_search_suggestions(\"mach\")\n# Returns: [\"machine learning\", \"machine vision\", \"macbook setup\"]\n\n# Autocomplete queries\ncompletions = agent.autocomplete_search(\"machine lear\")\n# Returns: [\"machine learning\", \"machine learning algorithms\", \"machine learning projects\"]\n</code></pre>"},{"location":"architecture/search-capabilities/#search-analytics","title":"Search Analytics","text":"<pre><code># Track search performance\nanalytics = agent.get_search_analytics()\nprint(f\"Average response time: {analytics['avg_response_time']}ms\")\nprint(f\"Cache hit rate: {analytics['cache_hit_rate']}%\")\nprint(f\"Most common queries: {analytics['top_queries']}\")\n</code></pre>"},{"location":"architecture/search-capabilities/#custom-search-filters","title":"Custom Search Filters","text":"<pre><code># Search with custom filters\nresults = agent.search_memory(\n    query=\"project documentation\",\n    filters={\n        \"memory_type\": [\"resource\", \"procedural\"],\n        \"date_range\": (\"2024-01-01\", \"2024-12-31\"),\n        \"sensitivity\": [\"low\", \"medium\"],\n        \"file_type\": [\"markdown\", \"pdf\"]\n    }\n)\n</code></pre>"},{"location":"architecture/search-capabilities/#integration-with-chat-agent","title":"Integration with Chat Agent","text":""},{"location":"architecture/search-capabilities/#contextual-search","title":"Contextual Search","text":"<p>The Chat Agent automatically enhances queries with context:</p> <pre><code># User asks: \"What did I work on?\"\n# Chat Agent enhances to: \"user activities work projects recent\"\n\n# User asks: \"Show me the API docs\"\n# Chat Agent enhances to: \"API documentation files resources programming\"\n</code></pre>"},{"location":"architecture/search-capabilities/#multi-turn-conversations","title":"Multi-Turn Conversations","text":"<pre><code># Turn 1: \"Tell me about machine learning\"\nsearch_context = [\"machine learning\", \"AI\", \"algorithms\"]\n\n# Turn 2: \"What about deep learning?\"  \nenhanced_query = \"deep learning \" + \" \".join(search_context)\n# Searches for: \"deep learning machine learning AI algorithms\"\n</code></pre>"},{"location":"architecture/search-capabilities/#troubleshooting","title":"Troubleshooting","text":""},{"location":"architecture/search-capabilities/#common-issues","title":"Common Issues","text":"Slow search performance <ol> <li> <p>Check GIN indexes are properly created: <pre><code>\\d+ your_table_name\n-- Look for GIN indexes on tsvector columns\n</code></pre></p> </li> <li> <p>Update table statistics: <pre><code>ANALYZE your_table_name;\n</code></pre></p> </li> <li> <p>Consider vacuuming the database: <pre><code>VACUUM ANALYZE your_table_name;\n</code></pre></p> </li> </ol> Poor search results <ol> <li>Verify search vectors are up to date</li> <li>Check query preprocessing</li> <li>Adjust field weights in configuration</li> <li>Try different search methods for comparison</li> </ol> Memory usage issues <ol> <li>Ensure using PostgreSQL BM25 (not in-memory)</li> <li>Optimize query limits</li> <li>Use field-specific searches when possible</li> <li>Consider result caching</li> </ol>"},{"location":"architecture/search-capabilities/#performance-tuning","title":"Performance Tuning","text":"<pre><code># mirix.yaml search configuration\nsearch:\n  default_method: \"bm25\"\n  default_limit: 50\n\n  bm25:\n    normalization: 32\n    field_weights:\n      title: 1.0\n      summary: 0.8\n      details: 0.6\n      content: 0.4\n\n  caching:\n    enabled: true\n    cache_size: 1000\n    ttl: 3600  # 1 hour\n</code></pre> <p>This powerful search system ensures that you can quickly and accurately find any information stored in your MIRIX memory, making your digital assistant truly intelligent and responsive.</p>"},{"location":"architecture/search-capabilities/#whats-next","title":"What's Next?","text":"<p>Learn how to use these search capabilities in practice:</p> <p>User Guide \u2192 </p>"},{"location":"assets/","title":"Assets Directory","text":"<p>This directory contains images, logos, and other media files used in the documentation.</p>"},{"location":"assets/#required-files","title":"Required Files","text":"<ul> <li><code>logo.png</code> - MIRIX logo (referenced in main documentation)</li> </ul>"},{"location":"assets/#adding-images","title":"Adding Images","text":"<p>To add images to your documentation:</p> <ol> <li>Place image files in this directory</li> <li>Reference them in markdown with relative paths:    <pre><code>![Alt text](assets/image-name.png)\n</code></pre></li> </ol>"},{"location":"assets/#logo-specifications","title":"Logo Specifications","text":"<p>For the main MIRIX logo: - Format: PNG with transparency - Recommended size: 200x200 pixels - Background: Transparent - Style: Should represent AI/memory/intelligence themes</p>"},{"location":"assets/#file-organization","title":"File Organization","text":"<pre><code>docs/assets/\n\u251c\u2500\u2500 logo.png           # Main MIRIX logo\n\u251c\u2500\u2500 screenshots/       # Application screenshots\n\u251c\u2500\u2500 diagrams/         # Architecture diagrams (if not using mermaid)\n\u2514\u2500\u2500 icons/            # Small icons and graphics\n</code></pre>"},{"location":"assets/#note","title":"Note","text":"<p>Currently, <code>logo.png</code> is referenced in the documentation but not present. You should add your MIRIX logo here or update the references in the documentation files to remove the logo image. </p>"},{"location":"getting-started/installation/","title":"Installation","text":"<p>This guide will walk you through setting up MIRIX on your system with PostgreSQL for optimal performance.</p>"},{"location":"getting-started/installation/#prerequisites","title":"Prerequisites","text":"<ul> <li>Python 3.11 or later</li> <li>A valid GEMINI API key</li> <li>PostgreSQL 17 (recommended for best performance)</li> </ul> <p>API Key Required</p> <p>You'll need a GEMINI API key to use MIRIX. Get one free from Google AI Studio.</p>"},{"location":"getting-started/installation/#step-1-clone-the-repository","title":"Step 1: Clone the Repository","text":"<pre><code>git clone https://github.com/Mirix-AI/MIRIX.git\ncd MIRIX\n</code></pre>"},{"location":"getting-started/installation/#step-2-set-up-environment-variables","title":"Step 2: Set up Environment Variables","text":"<p>Create a <code>.env</code> file in the project root:</p> <pre><code># Create .env file\ntouch .env\n</code></pre> <p>Add your GEMINI API key to the <code>.env</code> file:</p> <pre><code>GEMINI_API_KEY=your_api_key_here\n</code></pre>"},{"location":"getting-started/installation/#step-3-install-python-dependencies","title":"Step 3: Install Python Dependencies","text":"<pre><code>pip install -r requirements.txt\n</code></pre>"},{"location":"getting-started/installation/#step-4-database-setup","title":"Step 4: Database Setup","text":""},{"location":"getting-started/installation/#option-a-postgresql-recommended","title":"Option A: PostgreSQL (Recommended)","text":"<p>PostgreSQL provides better performance, scalability, and vector search capabilities.</p>"},{"location":"getting-started/installation/#install-postgresql-and-pgvector","title":"Install PostgreSQL and pgvector","text":"macOS (Homebrew)Ubuntu/DebianWindows <pre><code># Install PostgreSQL and pgvector\nbrew install postgresql@17 pgvector\n\n# Start PostgreSQL service\nbrew services start postgresql@17\n\n# Add PostgreSQL to your PATH\nexport PATH=\"$(brew --prefix postgresql@17)/bin:$PATH\"\n</code></pre> <pre><code># Install PostgreSQL\nsudo apt-get update\nsudo apt-get install postgresql postgresql-contrib\n\n# Install pgvector (see https://github.com/pgvector/pgvector for latest instructions)\n# Start PostgreSQL\nsudo systemctl start postgresql\n</code></pre> <ol> <li>Download PostgreSQL from postgresql.org</li> <li>Install pgvector following the official guide</li> <li>Start PostgreSQL service</li> </ol>"},{"location":"getting-started/installation/#create-database-and-enable-extensions","title":"Create Database and Enable Extensions","text":"<pre><code># Create the mirix database\ncreatedb mirix\n\n# Enable pgvector extension\npsql -U $(whoami) -d mirix -c \"CREATE EXTENSION IF NOT EXISTS vector;\"\n</code></pre>"},{"location":"getting-started/installation/#configure-environment-variables","title":"Configure Environment Variables","text":"<p>Add PostgreSQL configuration to your <code>.env</code> file:</p> <pre><code>GEMINI_API_KEY=your_api_key_here\n\n# PostgreSQL Configuration\n# Replace 'your_username' with your system username (find it with: echo $(whoami))\nMIRIX_PG_URI=postgresql+pg8000://your_username@localhost:5432/mirix\n</code></pre> <p>Username Setup</p> <p>This setup uses your system user for simplicity in development. For production, consider creating a dedicated PostgreSQL user with limited privileges.</p>"},{"location":"getting-started/installation/#option-b-sqlite-fallback","title":"Option B: SQLite (Fallback)","text":"<p>If PostgreSQL setup fails, MIRIX will automatically use SQLite. Simply omit the PostgreSQL environment variables from your <code>.env</code> file.</p> <p>SQLite Limitations</p> <p>SQLite works but has limitations in concurrent access and advanced search capabilities compared to PostgreSQL.</p>"},{"location":"getting-started/installation/#step-5-start-mirix","title":"Step 5: Start MIRIX","text":"<pre><code>python main.py\n</code></pre> <p>MIRIX will automatically create all necessary database tables on first startup and begin processing on-screen activities immediately.</p>"},{"location":"getting-started/installation/#troubleshooting","title":"Troubleshooting","text":""},{"location":"getting-started/installation/#common-postgresql-issues","title":"Common PostgreSQL Issues","text":"\\\"extension 'vector' is not available\\\" error <p>Install pgvector first: <pre><code># macOS\nbrew install pgvector\n\n# Then enable the extension\npsql -U $(whoami) -d mirix -c \"CREATE EXTENSION IF NOT EXISTS vector;\"\n</code></pre></p> \\\"permission denied to create extension\\\" error <p>The pgvector extension requires superuser privileges: <pre><code># Try connecting as postgres superuser\npsql -U postgres -d mirix -c \"CREATE EXTENSION IF NOT EXISTS vector;\"\n</code></pre></p> Connection refused or timeout <p>Make sure PostgreSQL service is running: <pre><code># macOS\nbrew services start postgresql@17\n\n# Linux\nsudo systemctl start postgresql\n</code></pre></p> \\\"database 'mirix' does not exist\\\" error <p>Create the database manually: <pre><code>createdb mirix\n\n# If createdb is not in PATH, use full path:\n# /opt/homebrew/opt/postgresql@17/bin/createdb mirix  # macOS with Homebrew\n</code></pre></p> \\\"pg_dump: No such file or directory\\\" error (during backup) <p>Set the correct PATH for PostgreSQL tools: <pre><code>export PATH=\"$(brew --prefix postgresql@17)/bin:$PATH\"\n</code></pre></p>"},{"location":"getting-started/installation/#verification","title":"Verification","text":"<p>Once installed, verify MIRIX is working:</p> <ol> <li>Check the logs - MIRIX should start capturing screenshots</li> <li>Test the chat - Send a simple message to the agent</li> <li>Check memory storage - Verify data is being stored in your database</li> </ol>"},{"location":"getting-started/installation/#next-steps","title":"Next Steps","text":"<p>Now that MIRIX is installed, learn how to use it:</p> <p>Quick Start Guide \u2192 </p>"},{"location":"getting-started/overview/","title":"Overview","text":"<p>MIRIX leverages a unique multi-layered memory system comprising six distinct memory components and eight specialized agents, ensuring that data is processed efficiently and securely.</p>"},{"location":"getting-started/overview/#what-is-mirix","title":"What is MIRIX?","text":"<p>MIRIX is a multi-agent personal assistant designed to track on-screen activities and answer user questions intelligently. By capturing real-time visual data and consolidating it into structured memories, MIRIX transforms raw inputs into a rich knowledge base that adapts to your digital experiences.</p>"},{"location":"getting-started/overview/#key-capabilities","title":"Key Capabilities","text":""},{"location":"getting-started/overview/#intelligent-screen-tracking","title":"Intelligent Screen Tracking","text":"<ul> <li>Takes screenshots every second</li> <li>Processes visual data in real-time</li> <li>Automatically consolidates information</li> </ul>"},{"location":"getting-started/overview/#multi-agent-architecture","title":"Multi-Agent Architecture","text":"<ul> <li>8 specialized agents working collaboratively</li> <li>6 memory components for organized data storage</li> <li>Coordinated workflow for efficient processing</li> </ul>"},{"location":"getting-started/overview/#advanced-search","title":"Advanced Search","text":"<ul> <li>PostgreSQL-native BM25 search</li> <li>Vector similarity search using embeddings</li> <li>Fuzzy matching capabilities</li> <li>Field-specific search across all memory types</li> </ul>"},{"location":"getting-started/overview/#privacy-security","title":"Privacy &amp; Security","text":"<ul> <li>All long-term data stored locally</li> <li>User-controlled privacy settings</li> <li>Secure screenshot handling with automatic cleanup</li> <li>Enterprise-grade PostgreSQL security</li> </ul>"},{"location":"getting-started/overview/#how-mirix-works","title":"How MIRIX Works","text":"<pre><code>flowchart TD\n    A[Screen Capture] --&gt; B[Meta Agent]\n    B --&gt; C{Content Analysis}\n    C --&gt; D[Core Memory&lt;br/&gt;Personal Info]\n    C --&gt; E[Episodic Memory&lt;br/&gt;Activities]\n    C --&gt; F[Semantic Memory&lt;br/&gt;Knowledge]\n    C --&gt; G[Procedural Memory&lt;br/&gt;Workflows]\n    C --&gt; H[Resource Memory&lt;br/&gt;Documents]\n    C --&gt; I[Knowledge Vault&lt;br/&gt;Credentials]\n\n    J[User Query] --&gt; K[Chat Agent]\n    K --&gt; L[Memory Search]\n    D --&gt; L\n    E --&gt; L\n    F --&gt; L\n    G --&gt; L\n    H --&gt; L\n    I --&gt; L\n    L --&gt; M[Intelligent Response]</code></pre>"},{"location":"getting-started/overview/#use-cases","title":"Use Cases","text":"<p>Digital Activity Tracking</p> <p>MIRIX automatically tracks your digital activities, from reading documents to browsing websites, creating a searchable timeline of your digital life.</p> <p>Context-Aware Assistance</p> <p>Ask questions about your recent activities: \"What was I reading about machine learning yesterday?\" or \"Where did I save that document about PostgreSQL?\"</p> <p>Knowledge Management</p> <p>Automatically extract and organize information from documents, websites, and applications you interact with.</p> <p>Workflow Documentation</p> <p>Learn and remember your common workflows, making it easier to repeat complex tasks.</p>"},{"location":"getting-started/overview/#system-requirements","title":"System Requirements","text":"<ul> <li>Python 3.11 or later</li> <li>PostgreSQL 17 (recommended) or SQLite</li> <li>GEMINI API key</li> <li>4GB RAM minimum, 8GB recommended</li> <li>10GB free disk space</li> </ul>"},{"location":"getting-started/overview/#whats-next","title":"What's Next?","text":"<p>Ready to get started? Follow our step-by-step installation guide:</p> <p>Installation Guide \u2192</p> <p>Or jump straight to using MIRIX:</p> <p>Quick Start \u2192 </p>"},{"location":"getting-started/quick-start/","title":"Quick Start","text":"<p>This guide will help you get MIRIX up and running quickly on your system.</p>"},{"location":"getting-started/quick-start/#prerequisites","title":"Prerequisites","text":"<p>Before starting, ensure you have:</p> <ul> <li>Python 3.11+ installed</li> <li>PostgreSQL 17 or SQLite for database</li> <li>GEMINI API key from Google AI Studio</li> <li>4GB RAM minimum (8GB recommended)</li> <li>10GB free disk space</li> </ul> <p>New Users</p> <p>If you haven't installed the prerequisites yet, check our Installation Guide first.</p>"},{"location":"getting-started/quick-start/#step-1-clone-and-setup","title":"Step 1: Clone and Setup","text":"<pre><code># Clone the MIRIX repository\ngit clone https://github.com/Mirix-AI/MIRIX.git\ncd MIRIX\n\n# Create and activate virtual environment\npython -m venv mirix-env\nsource mirix-env/bin/activate  # On Windows: mirix-env\\Scripts\\activate\n\n# Install dependencies\npip install -r requirements.txt\n</code></pre>"},{"location":"getting-started/quick-start/#step-2-configure-environment","title":"Step 2: Configure Environment","text":"<p>Create a <code>.env</code> file in the project root:</p> <pre><code># Database Configuration (choose one)\n# For PostgreSQL (recommended):\nDATABASE_URL=postgresql://username:password@localhost:5432/mirix_db\n\n# For SQLite (simpler setup):\n# DATABASE_URL=sqlite:///mirix.db\n\n# API Configuration\nGEMINI_API_KEY=your_gemini_api_key_here\n\n# Optional: Customize screenshot settings\nSCREENSHOT_INTERVAL=1  # seconds between screenshots\nMAX_SCREENSHOTS=1000   # maximum screenshots to store\n</code></pre> <p>API Key Required</p> <p>You must obtain a GEMINI API key from Google AI Studio to use MIRIX.</p>"},{"location":"getting-started/quick-start/#step-3-initialize-database","title":"Step 3: Initialize Database","text":"<p>If using PostgreSQL:</p> <pre><code># Create database\ncreatedb mirix_db\n\n# Initialize tables\npython scripts/init_db.py\n</code></pre> <p>If using SQLite, the database will be created automatically on first run.</p>"},{"location":"getting-started/quick-start/#step-4-start-mirix","title":"Step 4: Start MIRIX","text":"<pre><code># Start the main application\npython main.py\n</code></pre> <p>You should see output similar to:</p> <pre><code>[INFO] Initializing MIRIX Multi-Agent System...\n[INFO] Memory system initialized with 6 components\n[INFO] 8 agents loaded and ready\n[INFO] Screenshot capture started (interval: 1s)\n[INFO] MIRIX is now running and tracking your activities\n</code></pre>"},{"location":"getting-started/quick-start/#step-5-test-the-system","title":"Step 5: Test the System","text":""},{"location":"getting-started/quick-start/#basic-usage","title":"Basic Usage","text":"<p>Open a new terminal and test the chat functionality:</p> <pre><code># In a new terminal, activate the same environment\nsource mirix-env/bin/activate\n\n# Start interactive chat\npython chat.py\n</code></pre> <p>Try some example queries:</p> <pre><code>&gt; What have I been doing today?\n&gt; Show me recent documents I've worked on\n&gt; What websites did I visit in the last hour?\n</code></pre>"},{"location":"getting-started/quick-start/#backend-api-usage","title":"Backend API Usage","text":"<p>You can also interact with MIRIX programmatically:</p> <pre><code>from mirix import MIRIXAgent\n\n# Initialize the agent\nagent = MIRIXAgent()\n\n# Search memories\nresults = agent.search_memory(\"meeting notes\", memory_type=\"episodic\")\n\n# Get activity summary\nsummary = agent.get_activity_summary(hours=2)\nprint(summary)\n</code></pre>"},{"location":"getting-started/quick-start/#next-steps","title":"Next Steps","text":"<p>You're Ready!</p> <p>MIRIX is now tracking your screen activities and building your personal memory base.</p>"},{"location":"getting-started/quick-start/#explore-further","title":"Explore Further","text":"<ul> <li>Architecture Overview - Understand how MIRIX works</li> <li>User Guide - Learn advanced usage patterns</li> <li>Desktop App - Try the GUI interface</li> <li>API Reference - Build custom integrations</li> </ul>"},{"location":"getting-started/quick-start/#common-tasks","title":"Common Tasks","text":"<ul> <li>View Memory Components: Learn about the 6 memory types</li> <li>Search Capabilities: Explore advanced search features</li> <li>Performance Tuning: Check optimization tips</li> <li>Privacy Settings: Configure security options</li> </ul>"},{"location":"getting-started/quick-start/#troubleshooting","title":"Troubleshooting","text":""},{"location":"getting-started/quick-start/#common-issues","title":"Common Issues","text":"<p>Screenshot Permissions</p> <p>On macOS, you may need to grant screen recording permissions:</p> <ol> <li>Go to System Preferences &gt; Security &amp; Privacy &gt; Privacy</li> <li>Select Screen Recording</li> <li>Add your terminal application or Python executable</li> </ol> <p>Database Connection</p> <p>If you encounter database connection errors:</p> <pre><code># Check PostgreSQL status\npg_ctl status\n\n# Restart if needed\nbrew services restart postgresql\n</code></pre> <p>Memory Usage</p> <p>If MIRIX uses too much memory, adjust settings:</p> <pre><code># In config.py\nSCREENSHOT_INTERVAL = 2  # Reduce frequency\nMAX_MEMORY_SIZE = \"500MB\"  # Limit memory usage\n</code></pre>"},{"location":"getting-started/quick-start/#getting-help","title":"Getting Help","text":"<ul> <li>Documentation: Browse our comprehensive user guide</li> <li>Issues: Report bugs on GitHub Issues</li> <li>Contact: Email us at yuw164@ucsd.edu</li> </ul> <p>Ready to dive deeper? Check out our User Guide for advanced features and usage patterns. </p>"},{"location":"user-guide/backend-usage/","title":"Backend Usage","text":"<p>Learn how to use the MIRIX backend directly through Python code for maximum flexibility and control over your personal assistant.</p>"},{"location":"user-guide/backend-usage/#getting-started","title":"Getting Started","text":""},{"location":"user-guide/backend-usage/#initialize-the-agent","title":"Initialize the Agent","text":"<p>First, create and initialize your MIRIX agent:</p> <pre><code>from mirix.agent import AgentWrapper\n\n# Initialize agent with configuration\nagent = AgentWrapper(\"./configs/mirix.yaml\")\n</code></pre> <p>Configuration File</p> <p>Make sure your <code>mirix.yaml</code> configuration file and <code>.env</code> file are properly set up before initializing the agent.</p>"},{"location":"user-guide/backend-usage/#basic-operations","title":"Basic Operations","text":""},{"location":"user-guide/backend-usage/#sending-messages","title":"Sending Messages","text":""},{"location":"user-guide/backend-usage/#simple-text-messages","title":"Simple Text Messages","text":"<pre><code># Send basic text information\nagent.send_message(\n    message=\"The moon now has a president.\",\n    force_absorb_content=True\n)\n</code></pre>"},{"location":"user-guide/backend-usage/#multi-modal-content","title":"Multi-Modal Content","text":"<p>MIRIX can process text, images, and voice recordings together:</p> <pre><code># Send information with images and voice\nagent.send_message(\n    message=\"I'm working on a new project about machine learning.\",\n    image_uris=[\"/path/to/screenshot1.png\", \"/path/to/screenshot2.png\"],\n    voice_files=[\"base64_encoded_audio_1\", \"base64_encoded_audio_2\"],\n    force_absorb_content=True\n)\n</code></pre>"},{"location":"user-guide/backend-usage/#structured-multi-modal-messages","title":"Structured Multi-Modal Messages","text":"<p>For complex multi-modal conversations:</p> <pre><code># Multi-modal message format\nagent.send_message(\n    message=[\n        {'type': 'text', 'text': \"The moon now has a president. This is how she looks like:\"},\n        {'type': 'image', 'image_url': \"base64_encoded_image\"}\n    ],\n    image_uris=[\"/path/to/image_1\", \"/path/to/image_2\"],\n    voice_files=[\"base64_encoded_audio\"],\n    force_absorb_content=True\n)\n</code></pre>"},{"location":"user-guide/backend-usage/#conversational-queries","title":"Conversational Queries","text":"<pre><code># Ask questions about your activities\nresponse = agent.send_message(\"What was I working on yesterday?\")\nprint(\"MIRIX:\", response)\n\n# Get specific information\nresponse = agent.send_message(\"Show me documents about PostgreSQL\")\nprint(\"MIRIX:\", response)\n</code></pre>"},{"location":"user-guide/backend-usage/#understanding-parameters","title":"Understanding Parameters","text":""},{"location":"user-guide/backend-usage/#content-absorption-control","title":"Content Absorption Control","text":"<p>The <code>force_absorb_content</code> parameter controls when information is processed:</p> Value Behavior Use Case <code>True</code> Process immediately Important information, real-time updates <code>False</code> Batch processing (after 20 images) Regular browsing, background activities <pre><code># Immediate processing for important content\nagent.send_message(\n    message=\"Critical meeting notes from client call\",\n    force_absorb_content=True\n)\n\n# Batch processing for regular activities\nagent.send_message(\n    message=\"Browsing documentation\",\n    force_absorb_content=False\n)\n</code></pre>"},{"location":"user-guide/backend-usage/#input-types-and-formats","title":"Input Types and Formats","text":""},{"location":"user-guide/backend-usage/#message-parameter","title":"Message Parameter","text":"<p>Can be either a string or a structured list:</p> <pre><code># Simple string\nmessage = \"Working on the project documentation\"\n\n# Structured multi-modal format\nmessage = [\n    {'type': 'text', 'text': \"Here's the latest design mockup:\"},\n    {'type': 'image', 'image_url': \"data:image/png;base64,iVBORw0KGgoAAAANS...\"}\n]\n</code></pre>"},{"location":"user-guide/backend-usage/#image-handling","title":"Image Handling","text":"<pre><code># Use local file paths (recommended)\nimage_uris = [\n    \"/Users/username/Screenshots/screenshot1.png\",\n    \"/Users/username/Documents/diagram.jpg\"\n]\n\n# Avoid base64 encoding for image_uris to prevent memory issues\n</code></pre>"},{"location":"user-guide/backend-usage/#voice-files","title":"Voice Files","text":"<pre><code># Base64-encoded audio data\nvoice_files = [\n    \"UklGRnoGAABXQVZFZm10IBAAAAABAAEA...\",  # base64 audio\n    \"UklGRnoGAABXQVZFZm10IBAAAAABAAEA...\"   # base64 audio\n]\n</code></pre>"},{"location":"user-guide/backend-usage/#complete-workflow-examples","title":"Complete Workflow Examples","text":""},{"location":"user-guide/backend-usage/#example-1-daily-work-session","title":"Example 1: Daily Work Session","text":"<pre><code>from mirix.agent import AgentWrapper\n\n# Initialize\nagent = AgentWrapper(\"./configs/mirix.yaml\")\n\n# Morning briefing\nagent.send_message(\n    message=\"Starting work day. Today's priorities: finish documentation, review code, team meeting at 2 PM\",\n    force_absorb_content=True\n)\n\n# Work activities (batch processing)\nagent.send_message(\n    message=\"Working on API documentation\",\n    image_uris=[\"/screenshots/vscode_api_docs.png\"],\n    force_absorb_content=False\n)\n\nagent.send_message(\n    message=\"Code review session with team\",\n    image_uris=[\"/screenshots/github_pr.png\"],\n    force_absorb_content=False\n)\n\n# Important meeting (immediate processing)\nagent.send_message(\n    message=\"Team meeting - discussed Q4 roadmap, new feature priorities\",\n    voice_files=[\"base64_meeting_recording\"],\n    force_absorb_content=True\n)\n\n# End of day query\nresponse = agent.send_message(\"Summarize what I accomplished today\")\nprint(\"Today's Summary:\", response)\n</code></pre>"},{"location":"user-guide/backend-usage/#example-2-research-session","title":"Example 2: Research Session","text":"<pre><code># Research topic introduction\nagent.send_message(\n    message=\"Researching machine learning optimization techniques\",\n    force_absorb_content=True\n)\n\n# Reading and capturing research materials\nresearch_screenshots = [\n    \"/screenshots/arxiv_paper1.png\",\n    \"/screenshots/arxiv_paper2.png\",\n    \"/screenshots/github_implementation.png\"\n]\n\nagent.send_message(\n    message=\"Reading papers on gradient descent optimization\",\n    image_uris=research_screenshots,\n    force_absorb_content=False\n)\n\n# Taking notes\nagent.send_message(\n    message=[\n        {'type': 'text', 'text': \"Key insight from the research:\"},\n        {'type': 'text', 'text': \"Adam optimizer performs better than SGD for sparse gradients\"}\n    ],\n    force_absorb_content=True\n)\n\n# Query research findings\nfindings = agent.send_message(\"What are the key points about optimization techniques I discovered?\")\nprint(\"Research Findings:\", findings)\n</code></pre>"},{"location":"user-guide/backend-usage/#example-3-document-processing","title":"Example 3: Document Processing","text":"<pre><code># Processing multiple documents\ndocuments = [\n    \"/documents/project_proposal.pdf\",\n    \"/documents/technical_specs.docx\", \n    \"/documents/meeting_notes.md\"\n]\n\nfor doc_path in documents:\n    agent.send_message(\n        message=f\"Processing document: {doc_path}\",\n        image_uris=[doc_path] if doc_path.endswith(('.png', '.jpg')) else [],\n        force_absorb_content=True\n    )\n\n# Ask about document contents\nresponse = agent.send_message(\"What are the main points from the project proposal?\")\nprint(\"Document Summary:\", response)\n</code></pre>"},{"location":"user-guide/backend-usage/#advanced-features","title":"Advanced Features","text":""},{"location":"user-guide/backend-usage/#memory-search","title":"Memory Search","text":"<pre><code># Search across all memory types\nresults = agent.search_memory(\"machine learning algorithms\")\n\n# Search specific memory types\nresults = agent.search_memory(\n    query=\"project documentation\",\n    memory_types=[\"resource\", \"procedural\"],\n    limit=20\n)\n</code></pre>"},{"location":"user-guide/backend-usage/#backup-and-restore","title":"Backup and Restore","text":"<pre><code># Create backup\nresult = agent.save_agent(\"./backup_folder\")\nprint(result['message'])\n\n# Restore from backup\nagent = AgentWrapper(\"./configs/mirix.yaml\", load_from=\"./backup_folder\")\n</code></pre>"},{"location":"user-guide/backend-usage/#performance-optimization","title":"Performance Optimization","text":""},{"location":"user-guide/backend-usage/#batch-processing-strategy","title":"Batch Processing Strategy","text":"<pre><code># Collect multiple activities before processing\nactivities = []\n\n# Throughout the day\nactivities.append({\n    \"message\": \"Email review session\",\n    \"images\": [\"/screenshots/gmail.png\"]\n})\n\nactivities.append({\n    \"message\": \"Code development\", \n    \"images\": [\"/screenshots/vscode.png\"]\n})\n\n# Process batch at end of day\nfor activity in activities:\n    agent.send_message(\n        message=activity[\"message\"],\n        image_uris=activity[\"images\"],\n        force_absorb_content=False  # Batch processing\n    )\n\n# Force final processing\nagent.send_message(\n    message=\"End of day summary\",\n    force_absorb_content=True\n)\n</code></pre>"},{"location":"user-guide/backend-usage/#memory-management","title":"Memory Management","text":"<pre><code># Monitor memory usage\nmemory_stats = agent.get_memory_statistics()\nprint(f\"Total memories: {memory_stats['total_count']}\")\nprint(f\"Memory size: {memory_stats['total_size_mb']} MB\")\n\n# Clean up old memories (if supported)\nagent.cleanup_old_memories(days_old=30)\n</code></pre>"},{"location":"user-guide/backend-usage/#error-handling","title":"Error Handling","text":"<pre><code>try:\n    response = agent.send_message(\n        message=\"Test message\",\n        image_uris=[\"/invalid/path.png\"],\n        force_absorb_content=True\n    )\nexcept FileNotFoundError as e:\n    print(f\"Image file not found: {e}\")\nexcept Exception as e:\n    print(f\"Error processing message: {e}\")\n</code></pre>"},{"location":"user-guide/backend-usage/#integration-patterns","title":"Integration Patterns","text":""},{"location":"user-guide/backend-usage/#automated-screenshot-processing","title":"Automated Screenshot Processing","text":"<pre><code>import os\nimport time\nfrom pathlib import Path\n\ndef process_screenshots_directory(screenshot_dir, agent):\n    \"\"\"Process all new screenshots in a directory\"\"\"\n    screenshot_path = Path(screenshot_dir)\n    processed_file = screenshot_path / \".processed\"\n\n    # Load previously processed files\n    processed = set()\n    if processed_file.exists():\n        processed = set(processed_file.read_text().splitlines())\n\n    # Find new screenshots\n    new_screenshots = []\n    for img_file in screenshot_path.glob(\"*.png\"):\n        if str(img_file) not in processed:\n            new_screenshots.append(str(img_file))\n\n    if new_screenshots:\n        # Process new screenshots\n        agent.send_message(\n            message=f\"Processing {len(new_screenshots)} new screenshots\",\n            image_uris=new_screenshots,\n            force_absorb_content=len(new_screenshots) &gt; 10  # Force if many screenshots\n        )\n\n        # Update processed list\n        processed.update(new_screenshots)\n        processed_file.write_text(\"\\n\".join(processed))\n\n# Use the function\nagent = AgentWrapper(\"./configs/mirix.yaml\")\nprocess_screenshots_directory(\"/Users/username/Screenshots\", agent)\n</code></pre>"},{"location":"user-guide/backend-usage/#scheduled-processing","title":"Scheduled Processing","text":"<pre><code>import schedule\nimport time\n\ndef daily_summary():\n    \"\"\"Generate daily summary\"\"\"\n    agent = AgentWrapper(\"./configs/mirix.yaml\")\n    summary = agent.send_message(\"Provide a summary of today's activities\")\n\n    # Save summary to file or send notification\n    with open(f\"daily_summary_{time.strftime('%Y%m%d')}.txt\", \"w\") as f:\n        f.write(summary)\n\n# Schedule daily summary\nschedule.every().day.at(\"18:00\").do(daily_summary)\n\n# Keep the script running\nwhile True:\n    schedule.run_pending()\n    time.sleep(60)\n</code></pre>"},{"location":"user-guide/backend-usage/#best-practices","title":"Best Practices","text":""},{"location":"user-guide/backend-usage/#1-efficient-image-handling","title":"1. Efficient Image Handling","text":"<ul> <li>Use local file paths instead of base64 encoding for <code>image_uris</code></li> <li>Batch multiple images when possible</li> <li>Clean up temporary screenshots regularly</li> </ul>"},{"location":"user-guide/backend-usage/#2-strategic-force-processing","title":"2. Strategic Force Processing","text":"<ul> <li>Use <code>force_absorb_content=True</code> for important or time-sensitive information</li> <li>Use <code>force_absorb_content=False</code> for routine activities to enable batch processing</li> </ul>"},{"location":"user-guide/backend-usage/#3-structured-messaging","title":"3. Structured Messaging","text":"<ul> <li>Provide context in your messages</li> <li>Use descriptive messages that help with memory organization</li> <li>Include relevant metadata when available</li> </ul>"},{"location":"user-guide/backend-usage/#4-regular-maintenance","title":"4. Regular Maintenance","text":"<ul> <li>Create regular backups of your agent state</li> <li>Monitor memory usage and performance</li> <li>Clean up old or irrelevant memories periodically</li> </ul>"},{"location":"user-guide/backend-usage/#troubleshooting","title":"Troubleshooting","text":""},{"location":"user-guide/backend-usage/#common-issues","title":"Common Issues","text":"<p>Agent initialization fails</p> <p>Check your configuration files: <pre><code># Verify config file exists\nimport os\nprint(os.path.exists(\"./configs/mirix.yaml\"))\n\n# Check environment variables\nimport os\nprint(\"GEMINI_API_KEY\" in os.environ)\n</code></pre></p> <p>Image processing errors</p> <p>Verify image file paths: <pre><code># Check if image files exist\nimage_paths = [\"/path/to/image1.png\", \"/path/to/image2.png\"]\nfor path in image_paths:\n    if not os.path.exists(path):\n        print(f\"Missing: {path}\")\n</code></pre></p> <p>Memory or performance issues</p> <p>Monitor system resources: <pre><code>import psutil\nprint(f\"Memory usage: {psutil.virtual_memory().percent}%\")\nprint(f\"CPU usage: {psutil.cpu_percent()}%\")\n</code></pre></p>"},{"location":"user-guide/backend-usage/#whats-next","title":"What's Next?","text":"<p>Learn about advanced memory management techniques:</p> <p>Memory Management \u2192</p> <p>Or explore the API reference:</p> <p>Agent API \u2192 </p>"},{"location":"user-guide/desktop-app/","title":"Desktop App Guide","text":"<p>The MIRIX Desktop App provides a user-friendly graphical interface for interacting with your personal assistant and managing your digital activities.</p> <p>Coming Soon</p> <p>The desktop application is currently under development. This guide will be updated as features become available.</p>"},{"location":"user-guide/desktop-app/#overview","title":"Overview","text":"<p>The desktop app will offer:</p> <ul> <li>Real-time Activity Monitoring: Visual dashboard of your current activities</li> <li>Memory Explorer: Browse and search through your stored memories</li> <li>Chat Interface: Natural language conversations with your assistant</li> <li>Privacy Controls: Manage screenshot capture and data retention settings</li> <li>System Notifications: Stay informed about important activities and insights</li> </ul>"},{"location":"user-guide/desktop-app/#expected-features","title":"Expected Features","text":""},{"location":"user-guide/desktop-app/#main-dashboard","title":"Main Dashboard","text":"<pre><code>graph TB\n    A[Main Dashboard] --&gt; B[Activity Monitor]\n    A --&gt; C[Memory Browser]\n    A --&gt; D[Chat Interface]\n    A --&gt; E[Settings Panel]\n\n    B --&gt; F[Real-time Screenshots]\n    B --&gt; G[Activity Timeline]\n\n    C --&gt; H[Search Interface]\n    C --&gt; I[Memory Categories]\n\n    D --&gt; J[Conversation History]\n    D --&gt; K[Quick Actions]\n\n    E --&gt; L[Privacy Settings]\n    E --&gt; M[Performance Tuning]</code></pre>"},{"location":"user-guide/desktop-app/#activity-monitoring","title":"Activity Monitoring","text":"<ul> <li>Live Screenshot Feed: See what MIRIX is capturing in real-time</li> <li>Activity Timeline: Visual timeline of your digital activities</li> <li>Processing Status: Monitor memory consolidation and agent activity</li> <li>Performance Metrics: System resource usage and processing statistics</li> </ul>"},{"location":"user-guide/desktop-app/#memory-management","title":"Memory Management","text":"<ul> <li>Visual Memory Browser: Explore your six memory components</li> <li>Advanced Search Interface: Use all search methods with visual filters</li> <li>Memory Statistics: See memory usage and organization</li> <li>Export/Import Tools: Backup and restore your memories</li> </ul>"},{"location":"user-guide/desktop-app/#chat-interface","title":"Chat Interface","text":"<ul> <li>Rich Text Conversations: Natural language chat with formatting support</li> <li>Context Awareness: See what memories are being accessed for responses</li> <li>Multi-modal Input: Send text, images, and voice messages</li> <li>Conversation History: Browse and search past conversations</li> </ul>"},{"location":"user-guide/desktop-app/#privacy-security","title":"Privacy &amp; Security","text":"<ul> <li>Screenshot Controls: Enable/disable capture for specific applications</li> <li>Memory Retention Policies: Set automatic cleanup rules</li> <li>Sensitivity Management: Control access to sensitive information</li> <li>Activity Exclusions: Exclude specific activities from tracking</li> </ul>"},{"location":"user-guide/desktop-app/#current-workaround-backend-usage","title":"Current Workaround: Backend Usage","text":"<p>While the desktop app is in development, you can use the backend directly for full functionality.</p>"},{"location":"user-guide/desktop-app/#python-interface","title":"Python Interface","text":"<pre><code>from mirix.agent import AgentWrapper\n\n# Initialize the agent\nagent = AgentWrapper(\"./configs/mirix.yaml\")\n\n# Send information to process\nagent.send_message(\n    message=\"Working on documentation for MIRIX\",\n    image_uris=[\"/path/to/screenshot.png\"],\n    force_absorb_content=True\n)\n\n# Chat with your assistant\nresponse = agent.send_message(\"What have I been working on today?\")\nprint(response)\n</code></pre>"},{"location":"user-guide/desktop-app/#command-line-interface","title":"Command Line Interface","text":"<pre><code># Start MIRIX in background mode\npython main.py --daemon\n\n# Send a message via CLI\npython -c \"\nfrom mirix.agent import AgentWrapper\nagent = AgentWrapper('./configs/mirix.yaml')\nprint(agent.send_message('What did I work on yesterday?'))\n\"\n</code></pre>"},{"location":"user-guide/desktop-app/#development-status","title":"Development Status","text":""},{"location":"user-guide/desktop-app/#planned-features","title":"Planned Features","text":"<ul> <li>[ ] Desktop Application Framework: Electron or native Python GUI</li> <li>[ ] Real-time Activity Dashboard: Live monitoring interface</li> <li>[ ] Memory Browser: Visual exploration of memories</li> <li>[ ] Chat Interface: Rich conversation experience</li> <li>[ ] Settings Panel: Configuration management</li> <li>[ ] System Tray Integration: Background operation</li> <li>[ ] Notifications: Smart alerts and insights</li> <li>[ ] Backup/Restore GUI: Visual data management</li> </ul>"},{"location":"user-guide/desktop-app/#timeline","title":"Timeline","text":"<p>Development Roadmap</p> <p>The desktop app is planned for release in Q2 2025. Follow our GitHub repository for development updates.</p>"},{"location":"user-guide/desktop-app/#contributing","title":"Contributing","text":"<p>Interested in helping build the desktop app? We welcome contributions:</p> <ul> <li>UI/UX Design: Help design the user interface</li> <li>Frontend Development: Build the application interface</li> <li>Backend Integration: Connect the GUI to the MIRIX backend</li> <li>Testing: Help test and improve the user experience</li> </ul> <p>Contact us at <code>yuw164@ucsd.edu</code> or open an issue on GitHub to get involved.</p>"},{"location":"user-guide/desktop-app/#alternative-interfaces","title":"Alternative Interfaces","text":""},{"location":"user-guide/desktop-app/#web-interface-planned","title":"Web Interface (Planned)","text":"<p>A web-based interface is also planned, which will provide: - Browser-based access to MIRIX - Real-time updates via WebSocket - Mobile-responsive design - Cloud deployment options</p>"},{"location":"user-guide/desktop-app/#api-integration","title":"API Integration","text":"<p>For developers who want to integrate MIRIX into their own applications:</p> <pre><code># Example API integration\nfrom mirix.api import MIRIXAPI\n\napi = MIRIXAPI(config_path=\"./configs/mirix.yaml\")\n\n# Get recent activities\nactivities = api.get_activities(limit=10, time_range=\"today\")\n\n# Search memories\nresults = api.search_memories(\"machine learning\", limit=20)\n\n# Send new information\napi.absorb_content(\"Working on a new AI project\", images=[\"screenshot.png\"])\n</code></pre>"},{"location":"user-guide/desktop-app/#whats-next","title":"What's Next?","text":"<p>While waiting for the desktop app, learn how to use MIRIX through the backend:</p> <p>Backend Usage \u2192</p> <p>Or explore advanced features:</p> <p>Memory Management \u2192 </p>"},{"location":"user-guide/memory-management/","title":"Memory Management","text":"<p>Learn how to effectively manage and organize your MIRIX memories for optimal performance and retrieval.</p> <p>Documentation in Progress</p> <p>This section is being developed. For now, refer to the Backend Usage Guide for memory-related operations.</p>"},{"location":"user-guide/memory-management/#overview","title":"Overview","text":"<p>MIRIX's memory system is designed to automatically organize your digital activities into six distinct memory components. While most memory management happens automatically, you can optimize and tune the system for your specific needs.</p>"},{"location":"user-guide/memory-management/#memory-types-quick-reference","title":"Memory Types Quick Reference","text":"Memory Type Purpose Auto-Managed User Control Core Memory Personal preferences, identity \u2705 Manual updates Episodic Memory Activities and events \u2705 Cleanup policies Semantic Memory Knowledge and concepts \u2705 Concept merging Procedural Memory Workflows and processes \u2705 Workflow validation Resource Memory Documents and files \u2705 Archive policies Knowledge Vault Credentials and sensitive data \u26a0\ufe0f Manual classification"},{"location":"user-guide/memory-management/#coming-soon","title":"Coming Soon","text":"<p>This guide will cover:</p> <ul> <li>Memory Inspection: Browse and search your stored memories</li> <li>Manual Organization: Organize memories into custom categories</li> <li>Cleanup Strategies: Automatic and manual memory cleanup</li> <li>Performance Tuning: Optimize memory storage and retrieval</li> <li>Export/Import: Backup and migrate your memories</li> <li>Privacy Controls: Manage sensitive information</li> <li>Memory Analytics: Understand your digital patterns</li> </ul>"},{"location":"user-guide/memory-management/#current-operations","title":"Current Operations","text":"<p>For now, you can manage memories through the Python API:</p> <pre><code>from mirix.agent import AgentWrapper\n\n# Initialize agent\nagent = AgentWrapper(\"./configs/mirix.yaml\")\n\n# Search memories\nresults = agent.search_memory(\"machine learning\", limit=20)\n\n# Get memory statistics\nstats = agent.get_memory_statistics()\nprint(f\"Total memories: {stats['total_count']}\")\n\n# Create backup\nbackup_result = agent.save_agent(\"./backup\")\n</code></pre>"},{"location":"user-guide/memory-management/#whats-next","title":"What's Next?","text":"<p>While this guide is being developed, explore other areas:</p> <p>Backend Usage \u2192 Architecture Deep Dive \u2192 </p>"}]}